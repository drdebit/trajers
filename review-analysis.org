#+TITLE: Analysis of Referee Report JOAR-2019-358
#+SUBTITLE: "Sympathy for the Noise Trader: Limitations of Learning from Price"
#+AUTHOR: Review Analysis
#+DATE: 2026-02-06
#+OPTIONS: toc:t num:t

* Overview

This document provides a detailed analysis of the referee report for JOAR-2019-358, submitted to the /Journal of Accounting Research/ for the 55th Annual (2020) JAR Conference. The referee raised three substantive criticisms. We evaluate each against the relevant literature.

The referee's core claims are:
1. The model is incomprehensible and too distant from Grossman & Stiglitz (1980) to speak to debates about rational equilibrium.
2. Convergence without full rationality is already known (Gode & Sunder 1993), and incomplete learning is unsurprising given non-optimal agents.
3. The multi-signal nature of learning from price is well-known and can be shown theoretically.

Our conclusion: Criticism 1 identifies real presentation problems that should be fixed. Criticisms 2 and 3, however, mischaracterize the paper's contribution and are not supported by the papers the referee cites.

* Criticism 1: "The Model is Incomprehensible"

** What the Referee Says

#+BEGIN_QUOTE
The assumptions are not clearly stated, and the reader is expected to understand what is done by deciphering (what I think) is a java-based code. Even if the paper is a simulation, readers expect to know the distribution of the data-generating process and the equilibrium using conventional language (i.e., text and mathematics) and code is not a replacement for assumptions.
#+END_QUOTE

The referee also lists four specific departures from GS:
1. No information acquisition
2. Beliefs set exogenously without Bayes plausibility
3. Traders buy or sell a single share
4. No noise traders

** Assessment: Partially Fair, but Overstated

*** The presentation critique is legitimate

The paper does need a formal mathematical statement of its assumptions before presenting code. This is standard practice in accounting and finance. The code should supplement the mathematics, not replace it. The referee's identification of the language as "java-based" (it is Clojure, a Lisp dialect) underscores that the code alone is not communicating effectively. This is entirely fixable.

*** The claim that the model is "not anywhere close to GS" is overstated

The core setup --- informed investors who know a parameter, uninformed investors who must learn it from price, and a market that iterates toward convergence --- is directly from GS. The paper explicitly states: "It is not my intention to perfectly replicate GS' model, but rather to create a similar set of circumstances for investor learning." The departures, examined individually:

**** No information acquisition

True, but the paper studies what happens /after/ the informed/uninformed split, not the decision to become informed. GS's information acquisition result (the "impossibility" of perfectly efficient markets because information gathering becomes unprofitable) is a separate contribution from the learning mechanism that communicates information through price. The paper is concerned with the latter. Setting the informed fraction exogenously is consistent with how GS's own model operates once equilibrium is reached: there is a fixed fraction of informed traders, and the question is how well uninformed traders learn from them.

**** Exogenous beliefs without Bayes plausibility

This is a fair technical point. The uninformed investors' priors are drawn from $N(0,1)$ independently, which need not satisfy Bayes plausibility (i.e., the prior distribution of beliefs need not integrate to the true distribution of fundamentals). However:
- In GS, uninformed investors also have priors that are not derived from fundamentals --- they are simply "uninformed" and must learn from price.
- The paper could address this by constraining uninformed priors to be draws from the same distribution that generates fundamentals, ensuring Bayes plausibility. This is a robustness check, not a fundamental flaw.

**** Single-share trading

A simplification relative to GS, where demand is continuous and depends on risk aversion. However, the paper's core finding --- the identification problem of n parameters from 1 price --- does not depend on demand elasticity. Whether an investor buys 1 share or 100, the price signal still contains only aggregate information. Continuous demand would change the /rate/ of convergence but not the structural impossibility of decomposing the aggregate into components.

**** No noise traders

This is actually more interesting than damning. In GS, noise traders are /required/ to prevent perfect revelation of $\theta$ through price. Without noise, price perfectly reveals $\theta$, and no one needs to become informed, collapsing the market.

The paper's implicit (and unstated) insight is that with multiple parameters, you do not /need/ exogenous noise to prevent perfect revelation. The identification problem itself prevents it: even if price perfectly converges to the true aggregate value, investors still cannot decompose it into individual parameters. The "noise" is structural, arising from the dimensionality mismatch between the parameter space and the signal space. This should be stated as a contribution rather than left for the referee to discover.

** Recommended Response

Revise the paper to:
1. State all model assumptions in formal mathematical notation before presenting code.
2. Explicitly acknowledge departures from GS and explain why each is either immaterial to the core result or interesting in its own right.
3. Frame the absence of noise traders as a feature: the identification problem replaces exogenous noise as the barrier to perfect learning.

* Criticism 2: "Convergence Without Rationality is Known"

** What the Referee Says

#+BEGIN_QUOTE
The observation that agent without assuming full rationality can converge to equilibrium is well-known. This result can be found in, for example, Gode and Sunder (1993), uncited, in contexts where convergence to the equilibrium seems less obvious. [...] The second part of the contribution is that agents do not fully learn from price; but this is not very surprising if agents are not fully optimal and create noise from restricted trading rules with incorrect priors.
#+END_QUOTE

** Assessment: Misdirected

*** Gode & Sunder (1993) does not address the paper's contribution

Gode & Sunder (1993), "Allocative Efficiency of Markets with Zero-Intelligence Traders," published in the /Journal of Political Economy/, shows that "zero-intelligence" (ZI) traders submitting random bids and offers in a continuous double auction achieve near-perfect allocative efficiency, provided they are budget-constrained.

This paper is entirely orthogonal to the question at hand:

| Feature | Gode & Sunder (1993) | This Paper |
|---------|---------------------|------------|
| Information asymmetry | None. All traders have fixed, known private values. | Yes. Informed vs. uninformed investors. |
| Learning from price | None. Traders submit random orders. They do not observe or use price information to update beliefs. | Central to the model. Uninformed investors revise priors based on price movements. |
| Bayesian updating | None. | Approximated via averaging update rule. |
| Multiple parameters | No. Single good, single value per trader. | Yes. Security value is a vector of n parameters. |
| Core question | Can market mechanisms alone produce efficient prices without intelligent traders? | Can investors learn /individual/ valuation parameters from an /aggregate/ price signal? |

Gode & Sunder is a paper about /market mechanism design/. It asks whether the double auction institution can substitute for individual trader intelligence in achieving allocative efficiency. It does not involve any form of information aggregation, learning, or parameter estimation. Citing it as preempting a paper about multi-parameter investor learning from price is a category error.

*** Incomplete learning is not an artifact of agent suboptimality

The referee suggests that incomplete learning is "not very surprising if agents are not fully optimal and create noise from restricted trading rules with incorrect priors." This framing implies that smarter agents would learn perfectly. This is incorrect.

The structural issue is one of identification: a single price embodies the sum of n parameters, and any parameter vector that produces that sum is observationally equivalent. This is not a problem of agent intelligence --- it is a mathematical constraint:

$$\text{Given: } p = \sum_{i=1}^{n} \theta_i$$

An observer of $p$ alone cannot recover the individual $\theta_i$ for $n > 1$, regardless of the sophistication of the estimation method. A Bayesian optimizer, a maximum-likelihood estimator, or a neural network would all face the same constraint: the system is underdetermined.

Making agents more sophisticated (e.g., Bayesian with correct priors, or using regression on price history) could improve how efficiently they use the price signal and might produce different /distributions/ of individual parameter errors. But it cannot eliminate the fundamental identification problem. The paper could be strengthened by making this point explicitly and demonstrating robustness to alternative updating rules.

** Recommended Response

1. Cite Gode & Sunder (1993) and explain why it addresses a different question.
2. State the identification problem formally: one equation, n unknowns, infinitely many solutions.
3. Consider showing results under alternative updating rules (e.g., Bayesian, OLS) to demonstrate that the result is structural, not an artifact of the simple averaging rule.

* Criticism 3: "Multi-Signal Learning Impossibility is Known"

** What the Referee Says

#+BEGIN_QUOTE
The multi-signal nature of learning from price is also well-known in the muddling literature in rational expectations and can be shown theoretically without need for a full-on simulation. If there is a single signal to learn from but an n-dimensional original information set, the signal will not fully reveal the entire information set. This is certainly true in GS where the fundamental information is perturbed by noise traders; or Fischer and Verrecchia (2000) with an incentive shock perturbing the learning; or in multi-signal LENs where the effort is perturbed by noise (Feltham and Xie 1994). These mechanisms breaking how we can invert private information from a single signal are now well-known.
#+END_QUOTE

** Assessment: Partially Fair in Principle, but the Cited Papers Do Not Preempt the Contribution

The referee's core intuition --- that a single signal cannot fully reveal an $n$-dimensional information set --- is correct as a general principle, and the theoretical literature (Radner 1979, Jordan 1982) does establish the dimensional constraint. However, the /specific papers the referee cites/ do not address the same structural problem, and the paper's contribution is not preempted by them. We examine each in detail.

*** Fischer & Verrecchia (2000): "Reporting Bias"

**** What the paper does

Fischer & Verrecchia model a setting where a manager privately observes the firm's true earnings (a /single scalar/) and issues a biased report. The market, knowing the manager has an incentive to bias upward, rationally discounts the report. The paper derives the earnings response coefficient (the slope of price on reported earnings) and shows how it varies with the cost of biasing and the precision of the manager's private information.

**** Information structure

- One unknown: firm value (scalar)
- One signal: biased earnings report (scalar)
- One price
- The market's problem: filter a single signal through a known bias structure

**** Does it address multi-parameter learning from price?

No. The perturbation to learning in Fischer & Verrecchia comes from /strategic bias/, not from a dimensionality mismatch. There is a single parameter (true earnings), a single report, and a single price. The market can (and does) rationally discount the bias. The identification problem is 1-to-1, merely perturbed by noise. This is fundamentally different from the n-to-1 identification problem in the paper under review.

*** Feltham & Xie (1994): "Performance Measure Congruity"

**** What the paper does

Feltham & Xie study multi-task principal/agent contracts using the LEN (Linear-Exponential-Normal) framework. An agent exerts effort across multiple tasks. The principal observes performance measures that imperfectly capture the agent's multi-dimensional effort. The paper characterizes when multiple performance measures are valuable and how incongruent measures distort effort allocation.

**** Information structure

- Multiple unknowns: the agent's effort vector $\mathbf{e} = (e_1, \ldots, e_n)$
- Performance measures: linear functions of effort plus noise
- The principal's problem: design a contract that incentivizes the right effort allocation

**** Does it address multi-parameter learning from price?

No. There is a structural /analogy/: a single performance measure cannot capture multi-dimensional effort, just as a single price cannot reveal multi-dimensional valuation parameters. However:

1. The /domain/ is entirely different. Feltham & Xie is about /contracting/ (how to incentivize a known agent), not about /market learning/ (how investors extract unknown information from prices).
2. The /mechanism/ is different. In Feltham & Xie, the principal knows the mapping from effort to performance measures. The problem is designing incentives, not inferring unknowns.
3. The /implications/ are different. Feltham & Xie concludes that multiple performance measures are needed for congruent incentives. The analogous conclusion for markets --- that multiple signals are needed for investors to learn individual parameters --- is precisely the paper's contribution to the /market learning/ literature, which has not drawn this conclusion.

Citing Feltham & Xie as preempting a result about market learning is like citing the Heisenberg uncertainty principle as preempting an empirical study showing that a particular measurement apparatus cannot simultaneously measure position and momentum. The general principle may be known in one domain, but its application and implications in another domain constitute a contribution.

*** Grossman & Stiglitz (1980)

The referee says the impossibility of full revelation "is certainly true in GS where the fundamental information is perturbed by noise traders." But in GS, the perturbation comes from /exogenous noise traders/, not from a dimensionality mismatch. The information structure is:

$$u = \theta + \epsilon$$

Price is a noisy signal of the /single/ parameter $\theta$. The noise is added by noise traders, not created by the structure of the information space. GS does not consider the case where $\theta$ is a vector and price is a scalar. In fact, the entire mechanism of GS assumes that price /would/ perfectly reveal $\theta$ in the absence of noise --- that is the "impossibility" result. The paper under review shows that even without noise, price cannot reveal individual components when $\theta$ is a vector.

*** What the broader literature actually shows

A survey of the rational expectations and information aggregation literature reveals that the standard models maintain a 1:1 ratio between unknown parameters and price signals:

| Paper | Unknown Parameters | Price Signals | Ratio |
|-------|-------------------|---------------|-------|
| Grossman (1976) | 1 ($\theta$) | 1 (price) | 1:1 |
| Grossman & Stiglitz (1980) | 1 ($\theta$) | 1 (price + noise) | 1:1 |
| Verrecchia (1980) | 1 (asset return) | 1 (price) | 1:1 |
| Diamond & Verrecchia (1981) | 1 (asset return) | 1 (price) | 1:1 |
| Admati (1985) | K (multi-asset returns) | K (multi-asset prices) | 1:1 |
| Blume & Easley (1982) | K | K | 1:1 (explicitly required) |

Critically, Blume & Easley (1982) /explicitly state/ that signals and prices must be paired for Bayesian learning to function (pages 343--344). Diamond & Verrecchia (1981) model many traders each with a noisy signal about a /single scalar/ --- the aggregation is many-signals-to-one-parameter, which is well-identified.

Admati (1985) extends the framework to multiple assets, but with K assets there are K prices, preserving the 1:1 ratio. The case where a /single/ price must reveal /multiple/ parameters is simply not addressed.

*** The closest paper: Avery & Zemsky (1998)

The paper most relevant to the identification problem is Avery & Zemsky (1998), "Multidimensional Uncertainty and Herd Behavior in Financial Markets," published in the /American Economic Review/. They show that:

- With one dimension of uncertainty, a single price prevents herding (the price adjusts to reflect information, removing the incentive to herd).
- With two or three dimensions of uncertainty (value uncertainty, event uncertainty, and composition uncertainty), herding and mispricing arise /precisely because the single price mechanism cannot disentangle the multiple dimensions/.

This directly illustrates the identification failure. However:
1. Avery & Zemsky frame it as a /herding/ result, not as a general result about the limits of learning individual parameters from price.
2. They do not measure the /extent/ of parameter-level mispricing or how it scales with dimensionality.
3. They are not cited by the referee.

The existence of Avery & Zemsky (1998) shows that the /intuition/ is present in the literature, but the specific application to investor learning about individual valuation parameters --- and the empirical accounting literature's assumption that such learning occurs --- has not been explored.

*** The referee's logical error

The referee's argument contains a subtle logical error. The referee says:

#+BEGIN_QUOTE
These mechanisms breaking how we can invert private information from a single signal are now well-known.
#+END_QUOTE

But the "mechanisms" in the cited papers (noise traders, reporting bias, effort noise) are all /perturbations/ to a fundamentally identified system. Remove the noise trader from GS and price perfectly reveals $\theta$. Remove the reporting bias from Fischer & Verrecchia and the report perfectly reveals earnings. These are 1-to-1 systems with added noise.

The paper under review identifies a /structurally/ unidentified system: even in the total absence of noise, a single price cannot reveal n parameters when n > 1. This is a different and stronger result. The distinction is between:

- *Noisy identification*: The system has a unique solution, but noise prevents its exact recovery. More or better information can always improve the estimate. (GS, Fischer & Verrecchia)
- *Structural non-identification*: The system has infinitely many solutions. No amount of noise reduction can recover the individual parameters from the aggregate signal. (This paper)

This distinction is not made in any of the papers the referee cites.

** Recommended Response

1. Frame the contribution around the /identification/ problem explicitly, distinguishing structural non-identification from noisy identification.
2. Cite and discuss Avery & Zemsky (1998) as the closest related work, explaining how this paper extends their insight.
3. Cite and discuss the papers raised by the referee, explaining why each addresses a different question.
4. Add a formal impossibility result: for n > 1, no updating rule applied to a scalar price signal can uniquely recover the n-dimensional parameter vector.

* Summary Assessment

| Criticism | Fair? | Reason |
|-----------|-------|--------|
| 1. Model incomprehensible | Partially | Presentation needs formal math, but "not anywhere close to GS" is overstated |
| 2. Convergence known (Gode & Sunder) | No | Gode & Sunder studies a different question entirely; incomplete learning is structural, not from agent suboptimality |
| 3. Multi-signal learning known | Partially | The general principle is established (Radner/Jordan), but the referee's specific citations (GS, Fischer & Verrecchia, Feltham & Xie) all have 1:1 parameter-to-signal ratios and address noisy identification, not structural non-identification. The paper's specific contribution --- applying this to single-security investor learning and measuring scaling with $n$ --- is not preempted. |

The paper's core contribution --- that aggregate price efficiency does not imply individual parameter efficiency, and that this is a /structural/ limitation rather than a noise problem --- is not preempted by the cited literature. The primary weakness is presentation: the paper needs formal mathematics, explicit statement of departures from GS, and a clear framing of the identification problem as distinct from the noise problems studied in the existing literature.

* Comprehensive Literature Search (2026-02-06)

To verify the uniqueness of the paper's contribution, we conducted a comprehensive search of the literature across five dimensions: (1) multi-parameter price learning in finance theory, (2) rational expectations and information aggregation, (3) accounting and market efficiency, (4) agent-based market simulations, and (5) signal extraction in econometrics and macroeconomics. The search covered approximately 60 papers published between 1972 and 2026, with particular attention to work published since the original 2019 submission.

** The General Theoretical Result IS Known --- But It Concerns a Different Setting

Three foundational papers in general equilibrium theory establish the dimensionality constraint that underpins the paper's identification problem:

- *Radner (1979)*: "Rational Expectations Equilibrium: Generic Existence and the Information Revealed by Prices." /Econometrica/. Establishes that fully-revealing REE requires dim(price space) $\geq$ dim(state space). When this condition holds with finite states, full revelation is generic.

- *Allen (1982)*: "Strict Rational Expectations Equilibria with Diffuseness." /Journal of Economic Theory/. Explicitly states the necessary condition that the price space must have at least as high a dimension as the state space for generic full revelation.

- *Jordan (1982)*: "The Generic Existence of Rational Expectations Equilibrium in the Higher Dimensional Case." /Journal of Economic Theory/. Proves the converse: when dim(states) > dim(prices), fully revealing REE /generically do not exist/. This is the sharpest impossibility result and the direct theoretical precedent.

- *Pietra & Siconolfi (2008)*: "Trade and Revelation of Information." /Journal of Economic Theory/. Takes the impossibility as given and characterizes the /partially revealing/ equilibria that arise when there are more dimensions of uncertainty than prices.

*** What Radner and Jordan actually show --- and what they do not

It is critical to understand what "prices" and "states" mean in the Radner/Jordan framework. The "prices" in these papers are the /vector of commodity prices across an entire multi-commodity economy/ --- not the price of a single security. In an economy with $K$ commodities, there are $K$ prices, forming a $K$-dimensional price vector. The "states" are states of nature (e.g., whether it rains or shines), not individual valuation parameters of a single asset.

These are /existence results about equilibrium price functions/ in the tradition of Arrow-Debreu general equilibrium. They ask: does there exist a mapping from states of the world to commodity price vectors such that, in equilibrium, every trader can infer the state from observed prices? The answer is: generically yes when dim(prices) $\geq$ dim(states), generically no otherwise.

What Radner and Jordan do /not/ do:
- They do not model /investor learning dynamics/ --- their result is about whether a fully-revealing equilibrium /exists/, not about whether agents can /converge/ to it.
- They do not consider /single securities/ --- their setting is a multi-commodity exchange economy.
- They do not /measure/ the extent of mispricing when the condition fails.
- They do not connect to accounting or finance empirics.

*** The trivial violation for single securities

The key insight for the paper under review is this: *for any single security whose value depends on more than one parameter, the Radner/Jordan dimensionality condition is trivially and always violated.* A single security has one price (dim = 1). If its value depends on $n > 1$ parameters, dim(states) > dim(prices) by definition. The condition fails not as an edge case but as the universal default for real securities.

The finance literature has maintained the Radner/Jordan condition /by construction/: Grossman (1976) and GS (1980) model a single security with a single unknown parameter. Admati (1985) extends to $K$ assets with $K$ unknowns, preserving the 1:1 ratio. No standard model asks what happens to a single security with multiple underlying parameters --- yet this is the empirically relevant case, since any real security depends on many underlying factors.

The accounting and empirical finance literatures have compounded this by /assuming the problem away/: earnings response coefficients, event studies, and market efficiency tests all implicitly assume that investors can learn individual valuation parameters (e.g., accruals vs. cash flows, growth vs. profitability) from aggregate stock price movements. The structural identification problem shows this assumption is unfounded.

These papers establish the abstract mathematical principle. *However*, they are general equilibrium existence/non-existence results that concern multi-commodity economies, not single-security investor learning. They do not simulate markets, measure the extent of parameter-level mispricing, study how mispricing scales with $n$, or connect to the accounting literature's assumptions about investor learning. The paper under review is the first to draw the implication for the single-security investor learning problem.

** Applied Papers That USE the Confounding Structure

A second tier of papers builds models where a single price aggregates multiple unknowns, but each studies a different /consequence/:

| Paper | Unknowns | Signals | Consequence Studied |
|-------|----------|---------|-------------------|
| Lucas (1972) | Real + monetary shock | 1 (local price) | Monetary non-neutrality |
| Avery & Zemsky (1998) | 2--3 dimensions of uncertainty | 1 (asset price) | Herding behavior |
| Sockin & Xiong (2015) | Supply + demand shock | 1 (commodity price) | Feedback amplification |
| Goldstein & Yang (2015) | 2 fundamentals | 1 (stock price) | Information complementarities |
| Goldstein & Yang (2019) | 2 dimensions of uncertainty | 1 (stock price) | Disclosure crowds out /or/ crowds in information acquisition depending on disclosure type |
| Benhabib, Wang & Wen (2015) | Fundamental + sentiment | 1 (aggregate price) | Self-fulfilling equilibria |
| Rondina & Walker (2021) | Multiple shocks | Endogenous signals | Confounding dynamics |
| Adams (2024, WP) | Aggregate signals | Endogenous | States asset prices "necessarily fail" invertibility |
| Banerjee, Davis & Gondhi (2018) | Fundamentals + others' beliefs | 1 (stock price) | Transparency paradox |

*** Key details on the most relevant applied papers

**** Goldstein & Yang (2015): "Information Diversity and Complementarities in Trading and Information Acquisition"

/Journal of Finance/, 70(4), 1723--1765. Explicitly models security value as depending on *two fundamentals*, with different traders informed about different fundamentals. Because price is one-dimensional but the state space is two-dimensional, price cannot fully reveal both fundamentals simultaneously. The focus is on strategic complementarities in information acquisition, not on the impossibility per se or on how component-level errors scale with dimensionality. This is the closest finance theory paper.

**** Sockin & Xiong (2015): "Informational Frictions and Commodity Markets"

/Journal of Finance/, 70(5), 2063--2098. Commodity producers observe a single spot price reflecting *both* global economic fundamentals and supply noise. The feedback effects (producers cannot tell if a low price reflects weak demand or ample supply) generate real consequences. This is precisely a 2-unknowns-from-1-signal model, though applied to commodity markets with a feedback mechanism rather than to equity investor learning.

**** Adams (2024): "Macroeconomic Models with Incomplete Information and Endogenous Signals"

Working paper (University of Florida, December 2024; previously circulated as "Rational Expectations with Endogenous Information"). This paper provides the most rigorous modern treatment of the invertibility problem for endogenous signals.

Adams studies macroeconomic models where agents observe /endogenous/ signals --- signals that are themselves determined in equilibrium (like prices). He introduces two key conditions:

1. *Information Feedback Regularity (IFR)*: A /necessary/ condition for a signal-stable equilibrium to exist. It bounds the norm of the information feedback operator: $\|G\Theta\Xi(B_{A1}L^{-1} + B_{A0})\| < 1$. When this fails, the feedback from information to decisions to signals is explosive, and no stable equilibrium exists.

2. *Sufficient Idiosyncrasy Condition (SIC)*: A /sufficient/ condition for /global uniqueness/. The condition requires that the variance matrix of contemporaneous idiosyncratic shocks, $\Sigma_I = S_{X,0}(I - P_G)S^*_{X,0}$, be invertible. This requires at least as many idiosyncratic shocks as signals. SIC guarantees that all fixed points are signal-stable, and since Theorem 6 proves there can be at most one signal-stable fixed point, SIC implies global uniqueness.

The critical insight: *"Models where the endogenous signals are aggregates --- such as asset prices in the confounding dynamics example --- will necessarily fail this condition"* (p.22). When a signal is a pure aggregate (like a stock price), the projection matrix $P_G$ identifies only aggregate shocks. The matrix $I - P_G$ isolates idiosyncratic dimensions --- but aggregation /zeroes these out/. Therefore $\Sigma_I$ is singular, SIC fails, and uniqueness cannot be guaranteed. In his confounding dynamics example, SIC failure leads to multiple equilibria: both a full-information equilibrium and a "confounding dynamics" equilibrium coexist.

*Important distinction*: Adams's framework concerns the /macroeconomic/ setting --- whether a system of aggregate signals across an economy can identify the underlying state --- not the single-security investor learning problem studied in the paper under review. In Adams's models, the signals are aggregate variables (like asset prices or output) observed across the economy, and the question is whether the system of signals can identify macroeconomic states. The paper under review concerns a different setting: a single security with $n$ valuation parameters and one price.

However, the underlying mathematical mechanism is the same: when a signal is a pure aggregate, it cannot be inverted to recover the individual components that produced it. Adams shows that the stock price of a single security is a pure aggregate signal: $V = \sum \theta_i$ becomes a single number that zeroes out all idiosyncratic component information. This implies the invertibility condition necessarily fails. The paper's simulation demonstrates what that failure looks like in practice --- aggregate convergence coexisting with component-level non-identification, with MSE scaling with $n$.

**** Banerjee, Davis & Gondhi (2018): "When Transparency Improves, Must Prices Reflect Fundamentals Better?"

/Review of Financial Studies/, 31(6), 2377--2414. A single price conflates fundamental information with information about others' beliefs. Increasing transparency about fundamentals can make prices /less/ informative because investors respond by shifting to learning about others' beliefs rather than fundamentals.

**** Chabakauri, Yuan & Zachariadis (2022): "Multi-asset Noisy REE with Contingent Claims"

/Review of Economic Studies/, 89(5), 2445--2490. Studies the /solution/ to the dimensionality problem: with multiple assets (and hence multiple prices), it becomes possible to reveal aggregate shocks. However, only assets in the "replicating portfolio" for the aggregate risk factor are informationally relevant. This /confirms/ the structural non-identification problem for a single asset: one price cannot reveal a multidimensional state.

** Accounting Literature: Empirical Support Without Structural Explanation

Several streams in the accounting literature document empirical phenomena consistent with the structural identification problem, without identifying the structural cause:

*** Accrual anomaly literature

- *Sloan (1996)*: "Do Stock Prices Fully Reflect Information in Accruals and Cash Flows About Future Earnings?" /The Accounting Review/. Demonstrates that stock prices behave as if investors fixate on total earnings and fail to distinguish between the differential persistence of accruals vs. cash flows. This is direct evidence that the market does not learn individual component parameters from aggregate price.

- *Fairfield, Whisenant & Yohn (2003)*: "Accrued Earnings and Growth." /The Accounting Review/. Extended Sloan to broader earnings components; mispricing applies to growth in long-term net operating assets generally.

*** Information bundling literature

- *Ramanan (2015)*: "Promoting Informativeness via Staggered Information Releases." /Review of Accounting Studies/, 20, 537--558. DOI: 10.1007/s11142-014-9307-6. Formally shows that a firm releasing multiple pieces of information simultaneously cannot learn from the market's reaction which piece the market is responding to. Staggered release allows each piece to be separately priced. /This paper directly establishes that aggregate simultaneous pricing prevents learning about individual information components./ It is perhaps the most directly supportive paper in the accounting literature. (Note: previously misattributed to Dye & Sridhar, who are acknowledged for comments.)

- *Ahci, Martens & Sextroh (2022)*: "Information Bundling and Capital Market Feedback." Uses patent grant dates to show that bundling information impedes managerial learning from market feedback. When multiple signals are released simultaneously, the aggregate price response cannot be decomposed into individual component signals.

*** Managerial learning from prices

- *Gelsomin & Hutton (2023)*: "The Learning Hypothesis Revisited: A Discussion of Sani, Shroff and White (2023)." /Journal of Accounting and Economics/, 76, 101644. *This is perhaps the single most directly relevant paper in the accounting literature.*

  Gelsomin and Hutton critically examine the "Learning Hypothesis" --- the premise that managers learn useful, decision-relevant private information by observing outsiders' trading activity as reflected in stock prices. They identify /three key assumptions/ underlying the entire literature:

  1. Outsiders have private, relevant, material information unknown to managers.
  2. Outsiders' trading impounds the /value implications/ of that information into stock prices.
  3. Managers can /extract or infer/ outsiders' private, relevant information from observing stock prices --- and use it to improve their real investment decisions.

  They note that the first two assumptions are well-supported empirically, but /the third is not/: "There is no empirical proxy that directly demonstrates managerial learning... managerial learning from stock prices is simply /inferred or assumed/ from the documented changes in investment sensitivity to price (IS2P)" (p.2).

  Their *ice cube metaphor* is a perfect intuitive statement of the identification problem: "Imagine you place an ice cube in a bowl and leave the bowl on the counter. You can reasonably predict the shape of the ice cube in a couple of hours. [Forward inference is easy.] In contrast, however, now imagine you come across a bowl filled with water. What conclusions can you draw? Was the water previously frozen in the shape of a sphere, cube, or pyramid; one ice cube, multiple shapes, shavings, or crushed; or was the water frozen at all?" (p.2). This is precisely the n-to-1 identification problem: many different ice configurations (parameter vectors) produce the same bowl of water (aggregate price). The forward mapping (parameters → price) is well-defined; the inverse mapping (price → parameters) is not.

  They also invoke *Bond, Edmans & Goldstein (2012)*'s distinction between "forecasting price efficiency" (useful for predicting aggregate cash flows) and "revelatory price efficiency" (useful for informing specific real investment decisions). This maps /exactly/ to the paper's distinction between aggregate price convergence and component-level identification. Forecasting efficiency $\neq$ revelatory efficiency, for the precise structural reason that this paper identifies: one price cannot reveal $n$ parameters.

  Section 4 explicitly states: "There is something highly dissatisfying about the /Learning Hypothesis/... the literature leaves unanswered the /what/ and the /how/ managers learn from observing stock prices that affect their real investment decisions" (p.9).

  /Connection to the paper under review/: Gelsomin & Hutton identify /exactly/ the gap that this paper fills. They ask /why/ managers cannot extract individual information from aggregate stock prices --- the paper answers: because it is structurally impossible. The identification problem means that no amount of sophistication in observing prices can recover the individual components that went into them. Gelsomin & Hutton's unvalidated Assumption 3 is not merely unvalidated --- it is structurally unjustified for any security whose value depends on more than one parameter.

- *Bond, Edmans & Goldstein (2012)*: "The Real Effects of Financial Markets." /Annual Review of Financial Economics/. Notes that price efficiency for forecasting aggregate cash flows does not imply price efficiency for informing about individual investment decisions. Their "forecasting vs. revelatory efficiency" distinction is a key conceptual framework.

- *Gao & Liang (2013)*: "Informational Feedback, Adverse Selection, and Optimal Disclosure Policy." /Journal of Accounting Research/. Disclosure crowds out private information production, reducing what managers can learn from prices.

- *Armstrong, Heinle & Luneva (2024)*: "Financial Information and Diverging Beliefs." /Review of Accounting Studies/. When investors are uncertain about the precision of earnings as a signal, the same announcement can cause beliefs to /diverge/ rather than converge.

*** Experimental evidence

- *Davis, Korenok & Lightle (2025)*: "The Effects of Public Disclosures and Information Acquisition on Price Informativeness in a Multi-Attribute Asset Market." /Journal of Behavioral and Experimental Finance/, 47, 101084. DOI: 10.1016/j.jbef.2025.101084. A laboratory experiment with a two-component asset of uncertain value. The paper directly tests and confirms that learning individual components from aggregate prices requires strategic disclosure management --- the aggregate price alone does not spontaneously reveal individual attributes.

** Agent-Based / Computational Literature: A Notable Gap

The entire agent-based simulation literature on information aggregation uses *single-dimensional* fundamentals:

| Paper | Fundamental | Addresses n-from-1? |
|-------|-------------|---------------------|
| Gode & Sunder (1993) | Single private value | No |
| Jamal, Maier & Sunder (2024) | Single unknown state | No |
| Lopez-Lira (2025) | Single asset value (LLM agents) | No |
| Corgnet et al. (2020) | Single unknown state | No |
| Axtell & Farmer (2025, survey) | Various, all 1-D | No |
| LeBaron (2006, survey) | Various, all 1-D | No |

No computational or simulation study was found that models V = f($\theta_1, \ldots, \theta_n$) and asks whether traders can learn the individual $\theta_i$ from observing the single price. This is a genuine gap in the literature.

** Multi-Asset Models: The Standard Resolution

The standard theoretical resolution to the dimensionality problem is to add more prices (assets):

- *Admati (1985)*: $K$ assets, $K$ prices, preserving the 1:1 ratio.
- *Chabakauri, Yuan & Zachariadis (2022)*: Multiple assets including derivatives.
- *Chabakauri (2024, WP)*: Large markets with many assets --- "big data" from many prices.

This /confirms/ that the theoretical literature recognizes the dimensional constraint and resolves it by increasing the number of signals, not by extracting more from a single signal.

** Synthesis: What Is Unique and What Must Be Cited

*** The abstract mathematical principle is established --- in a different context (cite and acknowledge)

Jordan (1982) / Allen (1982) / Radner (1979) establish the dimensional impossibility in abstract multi-commodity general equilibrium. The paper must cite these and position its contribution relative to them. However, the relationship requires careful articulation:

- Radner and Jordan prove that /equilibrium price functions/ in multi-commodity economies cannot generically be fully revealing when dim(states) > dim(prices). Their "prices" are commodity price vectors, not single stock prices. Their results concern /existence of equilibria/, not /investor learning dynamics/.
- The paper under review shows that /for any single security with multiple underlying parameters/, the condition is trivially and always violated --- one price, $n > 1$ unknowns. This is not a special case of Radner/Jordan (which concerns multi-commodity economies) but rather a parallel application of the same mathematical principle (injectivity requires sufficient dimensionality) to a fundamentally different setting (single-security investor learning).
- The contribution is /not/ the mathematical principle itself, but its implication for a setting the theoretical literature has not examined and the empirical literature has assumed away.

*** The specific contribution IS unique

No paper found:

1. *Draws the implication* of the dimensionality constraint for the /single-security investor learning problem/. The Radner/Jordan condition is trivially and always violated for any real security, yet neither the theoretical finance literature (which maintains the condition by construction) nor the empirical accounting literature (which assumes the problem away) has noted this.
2. *Simulates* a market where $V = \sum \theta_i$ and *measures* component-level learning failure as a function of $n$.
3. *Connects* the structural identification problem to the *accounting literature's* implicit assumption that investors learn individual valuation parameters from price.
4. *Demonstrates* that aggregate price convergence *coexists* with component-level non-identification --- the market gets the sum right while being structurally unable to recover the parts.
5. *Frames* the absence of noise traders as a feature: structural non-identification replaces exogenous noise as the barrier to perfect learning. This insight is implicit in the theoretical literature but is never stated or explored.
6. *Measures* how MSE scales with the number of parameters $n$.

*** Recommended positioning for the revised paper

The paper should:

1. Cite Jordan (1982), Allen (1982), and Radner (1979), carefully distinguishing what they show (existence/non-existence of fully-revealing equilibria in multi-commodity economies) from what the paper shows (investor learning dynamics for a single security with multiple parameters). Emphasize that the Radner/Jordan condition is trivially violated for any single security with $n > 1$ parameters, yet neither the theoretical nor empirical literature has drawn this implication.

2. Cite Goldstein & Yang (2015) as the closest finance theory paper, noting that their model uses $n = 2$ fundamentals and one price but focuses on information complementarities, not on measuring component-level learning failure or connecting to accounting assumptions.

3. Cite Sockin & Xiong (2015) and Avery & Zemsky (1998) as applied examples that exploit the confounding structure for different purposes (commodity feedback and herding, respectively).

4. Cite Adams (2024) for the explicit statement that aggregate signals fail the invertibility condition. Note that Adams's framework concerns the macroeconomic setting (whether a system of aggregate signals across an economy can identify the underlying state) rather than the single-security problem, but the underlying mathematical mechanism is the same.

5. Cite Ramanan (2015) and the accrual anomaly literature (Sloan 1996) as accounting evidence that is /consistent with/ the structural explanation but has not been connected to it.

6. Position the simulation as filling a gap: the entire ABM literature uses single-dimensional fundamentals, and no prior study demonstrates the coexistence of aggregate convergence with component-level non-identification.

* Potential Additional References

*** Previously identified (from initial review analysis)

- *Avery & Zemsky (1998)*: "Multidimensional Uncertainty and Herd Behavior in Financial Markets." /American Economic Review/. Closest existing work on multi-dimensional identification failure from a single price.
- *Gode & Sunder (1993)*: Should be cited and distinguished, since the referee raised it.
- *Blume & Easley (1982)*: Explicitly states that signals and prices must be paired for Bayesian learning --- supports the paper's argument that the literature assumes the problem away.
- *Admati (1985)*: Multi-asset REE with K assets and K prices. Shows that the literature preserves the 1:1 ratio even when extending to multiple assets.
- *Hong & Stein (2007)*: "Disagreement and the Stock Market." Allows investors to observe only one of two signals. Relevant to partial information models.
- *Romer (1993)*: "Rational Asset-Price Movements Without News." Prices can move because trading reveals information imperfectly aggregated from multiple dimensions --- relevant but frames the result as about price movements, not learning.

*** Newly identified (from comprehensive literature search)

**** Must cite (directly relevant to positioning)

- *Jordan (1982)*: "The Generic Existence of Rational Expectations Equilibrium in the Higher Dimensional Case." /Journal of Economic Theory/. The sharpest impossibility result: when dim(states) > dim(prices), fully revealing REE generically do not exist.
- *Allen (1982)*: "Strict Rational Expectations Equilibria with Diffuseness." /Journal of Economic Theory/. States the dimensional necessary condition.
- *Radner (1979)*: "Rational Expectations Equilibrium: Generic Existence." /Econometrica/. Establishes that dim(prices) $\geq$ dim(states) is needed for generic full revelation.
- *Goldstein & Yang (2015)*: "Information Diversity and Complementarities in Trading and Information Acquisition." /Journal of Finance/. Closest finance theory paper: 2 fundamentals, 1 price.
- *Sockin & Xiong (2015)*: "Informational Frictions and Commodity Markets." /Journal of Finance/. Clean 2-unknowns-from-1-price applied model.
- *Adams (2024)*: "Macroeconomic Models with Incomplete Information and Endogenous Signals." Working paper (University of Florida). Introduces Information Feedback Regularity and Sufficient Idiosyncrasy Condition; proves aggregate signals (like asset prices) necessarily fail invertibility.
- *Ramanan (2015)*: "Promoting Informativeness via Staggered Information Releases." /Review of Accounting Studies/, 20, 537--558. Formally shows bundled signals prevent component-level learning.

- *Gelsomin & Hutton (2023)*: "The Learning Hypothesis Revisited." /Journal of Accounting and Economics/, 76, 101644. Explicitly questions whether managers can extract individual information from aggregate stock prices; ice cube metaphor perfectly illustrates the identification problem; identifies the unvalidated assumption that this paper shows is structurally unjustified.

**** Should cite (strongly supportive or closely related)

- *Goldstein & Yang (2019)*: "Good Disclosure, Bad Disclosure." /Journal of Financial Economics/. Disclosure about one dimension can crowd out /or/ crowd in information acquisition about another, depending on the type of information disclosed.
- *Sloan (1996)*: "Do Stock Prices Fully Reflect Information in Accruals and Cash Flows?" /The Accounting Review/. Empirical evidence consistent with the structural explanation.
- *Benhabib, Wang & Wen (2015)*: "Sentiments and Aggregate Demand Fluctuations." /Econometrica/. Price conflates fundamental and sentiment; signal extraction cannot separate them.
- *Rondina & Walker (2021)*: "Confounding Dynamics." /Journal of Economic Theory/. Dynamic version of the confounding problem.
- *Banerjee, Davis & Gondhi (2018)*: "When Transparency Improves, Must Prices Reflect Fundamentals Better?" /Review of Financial Studies/. A single price conflates fundamentals with information about others' beliefs.
- *Pietra & Siconolfi (2008)*: "Trade and Revelation of Information." /Journal of Economic Theory/. Characterizes partial revelation when dim(uncertainty) > dim(prices).
- *Chabakauri, Yuan & Zachariadis (2022)*: "Multi-asset Noisy REE with Contingent Claims." /Review of Economic Studies/. Shows multiple prices needed to resolve the dimensional constraint.
- *Bond, Edmans & Goldstein (2012)*: "The Real Effects of Financial Markets." /Annual Review of Financial Economics/. Aggregate price efficiency $\neq$ component efficiency.

**** Consider citing (contextually relevant)

- *Lucas (1972)*: The original confounding model (2 shocks, 1 price).
- *Ahci, Martens & Sextroh (2022)*: Experimental evidence that information bundling impedes learning.
- *Armstrong, Heinle & Luneva (2024)*: Precision uncertainty causes belief divergence.
- *Jamal, Maier & Sunder (2024)*: Recent ABM work (cite to show the gap in the computational literature).
- *Axtell & Farmer (2025)*: ABM survey (cite to show the gap).
- *Lou, Parsa & Ray (2019) / Rostek & Weretka (2019)*: Multidimensional signals but 1-D fundamental --- shows the distinction between signal dimensionality and fundamental dimensionality.
- *Vives (2008)*: /Information and Learning in Markets/ (textbook). Comprehensive reference on information aggregation.
- *Siga & Mihm (2021)*: "Information Aggregation in Competitive Markets." /Theoretical Economics/. Studies multidimensional states with a single price as aggregation mechanism.
