#+TODO: TODO(t) IN-PROGRESS(i) | DONE(d)
#+OPTIONS: toc:nil
#+Latex_header: \usepackage{setspace}
#+latex_header: \doublespacing
#+latex_header: \usepackage[citestyle=authoryear,bibstyle=authortitle,hyperref=true,backref=true,maxcitenames=3,uniquename=false,maxbibnames=99,url=true,backend=biber,natbib=true] {biblatex}
#+latex_header: \usepackage[margin=1in]{geometry}
#+latex_header: \usepackage{array}
#+latex_header: \usepackage{amsmath}
#+latex_header: \usepackage{amssymb}
#+latex_header: \usepackage{amsthm}
#+latex_header: \newtheorem{assumption}{Assumption}
#+latex_header: \newtheorem{proposition}{Proposition}
#+latex_header: \newtheorem{definition}{Definition}
# Hack for square brackets
#+latex_header: \newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
#+latex_header: %\ExecuteBibliographyOptions{parentracker=false}

#+latex_header: \makeatletter

#+latex_header: \newrobustcmd*{\parentexttrack}[1]{%
  #+latex_header: \begingroup
  #+latex_header: \blx@blxinit
  #+latex_header: \blx@setsfcodes
  #+latex_header: \blx@bibopenparen#1\blx@bibcloseparen
  #+latex_header: \endgroup}

#+latex_header: \AtEveryCite{%
  #+latex_header: \let\parentext=\parentexttrack%
  #+latex_header: \let\bibopenparen=\bibopenbracket%
  #+latex_header: \let\bibcloseparen=\bibclosebracket}

#+latex_header: \makeatother
#+latex_header: \addbibresource{/home/matt/Dropbox/BibLaTeX/library.bib}

# # Start document
# #+title: Sympathy for the Noise Trader
# #+author: Matthew D. DeAngelis
\begin{titlepage}
\singlespacing
\begin{center}
\LARGE Sympathy for the Noise Trader: Limitations to Learning from Price
\vspace*{35mm}

\normalsize Matthew D. DeAngelis\textsuperscript{a}

\textit{Georgia State University}
\end{center}

\vspace*{\fill}
\textsuperscript{a} Corresponding author. School of Accountancy, J. Mack Robinson College of Business, Georgia State University, 35 Broad Street, Room 512, Atlanta GA, 30302. Phone: (404) 413-7214. E-mail: mdeangelis@gsu.edu

\vspace*{10mm}
I gratefully acknowledge the contributions of Kris Allee, John Campbell, Vic Lee, Ruiyan Luo, Joao Mota, Greg Waymire, James Wilhelm, Jing Zhang and Lu Zhang.
\end{titlepage}

#+LATEX: \newpage

#+BEGIN_CENTER
\LARGE Sympathy for the Noise Trader: Limitations to Learning from Price
#+END_CENTER
\vspace*{40mm}
#+BEGIN_abstract

Empirical studies in accounting and finance assume that the market not only incorporates all available information into price, but also forms precise and efficient estimates of individual valuation parameters such as the persistence of earnings. However, prevailing models of investor learning do not provide a mechanism by which investors distinguish between multiple parameters when observing aggregate price movements. I extend the model in citet:grossmanImpossibilityInformationallyEfficient1980 to accommodate multiple parameters and show that this creates a structural identification problem: a single price signal cannot uniquely determine an $n$-dimensional parameter vector for $n > 1$. For any single security whose value depends on more than one parameter, this condition is trivially and always violated. The abstract mathematical principle was established in multi-commodity general equilibrium by citet:radnerRationalExpectationsEquilibrium1979 and citet:jordanGenericExistenceRational1982, but its implication for the single-security investor learning problem --- and for the assumptions embedded in empirical accounting and finance --- has not been drawn. Using an agent-based simulation, I demonstrate that the market prices aggregate *all* information efficiently but does not achieve efficient estimates of *individual parameters*, and that component-level mispricing increases with the number of parameters. This result holds regardless of the sophistication of the updating rule and is driven by the dimensionality mismatch between the information space and the price signal, not by noise or bounded rationality.

#+END_abstract
#+LATEX: \newpage

* Introduction
  In this paper, I explore the limitations of learning from price. Specifically, I extend previous models of investor learning to accommodate the simultaneous processing of multiple information signals. Prior models focus on learning from price as a perfect or noisy signal for a single informational parameter (citet:grossmanImpossibilityInformationallyEfficient1980,diamondInformationAggregationNoisy1981). However, in practice information rarely arrives in isolation: detailed numerical or textual information can be released as part of an earnings announcement; managers can issue a forecast in conjunction with earnings; and an annual report can contain hundreds of pages. I investigate what happens when uninformed investors must revise their estimates of multiple valuation parameters from movements in a single price signal.

  The core insight is one of identification. In existing models, a single price communicates a single unknown parameter, and the system is exactly identified: an investor observing price can, in principle, recover the unknown. When price reflects multiple parameters simultaneously, however, the system becomes structurally underidentified. A single scalar price constrains an $n$-dimensional parameter vector to lie on an $(n-1)$-dimensional hyperplane, leaving infinitely many parameter combinations consistent with any observed price. This is not a problem of noise, bounded rationality, or suboptimal updating --- it is a mathematical constraint that applies regardless of investor sophistication.

  Following citet:grossmanImpossibilityInformationallyEfficient1980 (GS), I create an agent-based simulation to model the process of uninformed investors learning private information from informed investors. Specifically, I create informed agents with perfect knowledge of the valuation parameters and uninformed agents that must learn those parameters by observing the price signal. Consistent with GS, I find that the market converges on the ``true'' price of the security and that uninformed investors arrive at an accurate estimate of the parameter when the security's value depends on a single parameter.

  Also consistent with GS, I find that the market continues to converge to the true value of the security when I extend the security to include two informational parameters. In this sense, the market is efficient in that the price impounds all available information. However, the market's information set is neither complete nor accurate: the consensus estimate of the individual parameters across individual traders does not converge on the true value of those parameters. This is because uninformed traders cannot distinguish the values of the individual parameters from the aggregate price movement. Instead, they approximate a linear combination of the parameters that is consistent with the observed price. As such, whether market price aggregates *all* available information is distinct from whether the market learns *each component* of information. I also find evidence to suggest that investors learn individual parameters less well as the number of parameters grows beyond two.

  I make three primary contributions to the literature. First, I identify a structural distinction between /aggregate price efficiency/ and /component parameter efficiency/ that is absent from existing models. Although empirical researchers often refer to a cognitive model of the market, in which the market ``learns'' or ``estimates'' the value of a security and its components, a precise model of what the market ``knows'', and how, is not specified. Further, many studies appear to assume that an efficient price implies an efficient valuation of each individual parameter that makes up price, or that investors learn specifically what weight to assign to current earnings, detailed balance sheet information, linguistic tone, etc., from price movements around earnings releases. Since the market only maintains a single informational item, price, that is distinct from the models held by individual investors, I ask whether the market can be said to ``know'' value beyond price. I find that the market can converge upon the correct price of a security without establishing a correct consensus estimate on the individual parameters of value. This result is consistent with what empirical researchers have long acknowledged regarding their own limitations in separating the price impact of multiple signals. However, market models do not incorporate these limitations when modeling investor learning. In clarifying this disconnect between theory and empirical practice, my study helps to explain empirical evidence of price drift after significant information releases such as earnings (citet:bernardPostEarningsAnnouncementDriftDelayed1989,bernardEvidenceThatStock1990), the ``earnings fixation'' documented by citet:sloanStockPricesFully1996, investor reliance on returns over fundamental information (citet:blankespoorWhyIndividualInvestors2019), and the habit by investors to collect and respond to so-called ``stale'' information (citet:tetlockAllNewsThats2011,drakeUsefulnessHistoricalAccounting2016a). Because valuation components evolve at different rates --- cash flows persist more than accruals, growth rates differ from discount rates --- the inability to decompose the aggregate signal affects not only current understanding but also the ability to predict future prices. The structural constraint thus provides a foundation for understanding why supplementary signals (disclosures, analyst reports, media coverage) are valuable: each resolves one dimension of the identification problem that price alone cannot.

  Second, I show that the identification problem I describe is /structural/ rather than a consequence of noise or bounded rationality. The mathematical principle that a lower-dimensional signal cannot uniquely encode a higher-dimensional state was established by citet:radnerRationalExpectationsEquilibrium1979, citet:allenStrictRationalExpectations1982, and citet:jordanGenericExistenceRational1982 as an existence result for general equilibrium: when the state space has more dimensions than the price vector, fully-revealing equilibria generically do not exist. However, these are abstract results about multi-commodity economies; the ``prices'' in Radner and Jordan are the vector of commodity prices across the economy, not the price of a single security. For any single security whose value depends on multiple parameters, the dimensional condition is trivially and always violated --- yet the finance and accounting literatures have not drawn this implication. My contribution is to apply this principle to the specific context of investor learning from a single stock price, to demonstrate it computationally, and to measure its consequences. In doing so, I distinguish my result from the existing literature on noisy rational expectations, in which incomplete learning arises from exogenous perturbations (noise traders in citet:grossmanImpossibilityInformationallyEfficient1980, reporting bias in citet:fischerReportingBias2000, effort noise in citet:felthamPerformanceMeasureCongruity1994). In those models, the information system is fundamentally identified --- removing the noise would allow perfect recovery of the unknown parameter. In my setting, even in the complete absence of noise, a single price cannot reveal individual parameters when the security's value depends on more than one. The underidentification is inherent in the dimensionality mismatch between the parameter space and the signal space, and no updating rule --- however sophisticated --- can overcome it.

  Third, I highlight the utility of simulations to explore theoretical questions in accounting research. Simulations provide an opportunity to examine complex systems in which behavior is unpredictable and dependent on interactions between agents (citet:lebaronAgentbasedComputationalFinance2000). They also provide an intuitive way to construct and experiment with analytical models and to make those models accessible to empirical researchers. In the spirit of reproducible research, I provide all of the code used in this study directly in the paper so that editors, reviewers and future researchers can replicate, stress-test and extend my results. My code is written in a Lisp dialect, Clojure, which makes it easy to modify and extend to new models and experiments for investigating investor and market information processing. I ask that researchers utilizing this code also open source their modifications to encourage collaboration, save researcher time, and improve understanding of how researcher choices influence results.

  # In supplemental analyses I further extend the Grossman and Stiglitz model to consider investors who are only partially informed. In contrast to my results above, I find that markets composed solely of partially informed investors consistently converge on a consensus estimate of price, but that this estimate is not consistently the true value. As a result, my model does not suggest that the market effectively pools diverse information when that information is distributed across multiple parameters and suggests that market efficiency depends on other coordination mechanisms. To investigate one possible supplement to price, I implement a form of "social media" in which investors are able to communicate their private beliefs on a single parameter. I find...

* Literature Review and Hypothesis Development
  :PROPERTIES:
  :CUSTOM_ID: litreview
  :END:

** Learning from price
   What precisely is meant by market efficiency, as well as what and how investors learn from price, is usually not specified in empirical studies. However, a discussion in citet:tetlockGivingContentInvestor2007, regarding how the market is expected to respond to the release of media articles, is instructive as to the assumptions commonly made.

   citet:tetlockGivingContentInvestor2007 considers how the market is expected to respond under three alternative situations:
1) Media articles convey new information to the market. In this case, the market price is expected to adjust and this adjustment is expected to persist.
2) Media articles convey old information to the market. In this case, the market price is not expected to adjust, since the information is already incorporated in price.
3) Media articles reflect ``sentiment'' in the market. In this case, the market price is expected to adjust, but this adjustment is expected to reverse as arbitrageurs trade back to fundamentals.
Each alternative requires that investors not only know price, but know why price is what it is. How else would an investor distinguish between old information and new information, if he is not able to observe price and infer the information contained within it? Likewise with sentiment: an investor must understand whether private information exists and whether price incorporates that information before concluding that an observed price movement has no informational basis. A similar set of assumptions is commonly used in the accounting literature. In citet:kormendiEarningsInnovationsEarnings1987, for example: ``Implicit in [Equation] 1 is the efficient markets assumption that only the new information in earnings affects returns.'' (page 326). This suggests that the market develops an efficient estimate, not just of the total information available to value the security, but of earnings specifically. Moreover, while Kormendi and Lipe make this assumption over an entire year's time, subsequent studies use an event-study framework in which the market is presumed to fully price earnings within a few days, or even hours. In other words, investors are presumed to exit the trading process with a correct estimate of the weight to assign to earnings, at least on average, so that future price movements are determined only by earnings innovations.

  These assumptions regarding investor and market learning are based on models showing price to be a powerful information communicator, of which citet:grossmanImpossibilityInformationallyEfficient1980 (GS) is one of the most prominent. GS utilize a market model in which the return from a single risky security is based on a single informational parameter, so that return is represented as:
\begin{equation}
u = \theta + \epsilon
\end{equation}
where $\theta$ represents the mean of the return distribution. Investors can purchase $\theta$ and become informed investors. Otherwise, uninformed investors can learn $\theta$ through price movements.

  GS' main finding is that price can be too informative: it communicates the valuation parameter so well that it creates a disincentive for investors to become informed. Specifically, because the benefits of becoming informed decline as more investors become informed, communication of information through price reduces the likelihood that the marginal investor chooses to purchase information. In order for the market to reach equilibrium, GS finds that market prices must convey $\theta$ with noise so that returns to information gathering are more stable.

  Price can become a sufficient statistic for unobservable information even in the absence of fully informed investors. In citet:grossmanEfficiencyCompetitiveStock1976, citet:diamondInformationAggregationNoisy1981, and citet:verrecchiaConsensusBeliefsInformation1980, investors are either endowed with or can purchase random draws from the return variable, so that no individual investor knows the true mean of returns. However, their collective information converges on the true mean, again allowing individual investors to rely solely on price and discouraging them from collecting information. As above, in order for markets to function, price must be made less informative or, as noted in Diamond and Verrecchia, ``[n]oise is critical to the analysis of the model's equilibrium'' (page 233). This noise ``represents factors other than information which cause prices to vary'' (page 234), allowing informed investors to profit from information gathering.

  Other models of noisy investor learning include citet:brayLearningEstimationStability1982 and citet:brayRationalExpectationsEquilibria1986, in which investors must learn to form rational expectations from price because the relationship between price and the security's underlying value changes over time. In these models investors use econometric models such as linear regression to estimate this relationship. citet:fourgeaudLearningProceduresConvergence1986 allow decision-makers to predict an unobservable endogenous factor from observable exogenous factors. In each of these cases, however, investors tie a single price to a single information parameter.

  As pointed out in citet:verrecchiaConsensusBeliefsInformation1980, the market can be said to have learned the distribution of value even if all investors do not agree. Instead, investors could be dispersed around the true mean on the univariate prior. The disagreement around the prior results in trading, but the same number of investors revise their beliefs upwards as downwards, in the same amounts. In this case there is trading, at least for a time, but the trading results in no price movement. In both cases, however, the market can be said to have reached both an efficient estimate of price, or the total value of the security, as well as each of the components of value (since there is only a single component).

  Models that do consider multiple information parameters combine them with multiple prices. Usually this constitutes a simulation of an entire market in which investors trade across multiple securities in an effort to achieve an efficient price equilibrium.  citet:blumeLearningBeRational1982 is a notable early contribution to this literature, along with studies such as citet:axtellComplexityExchange2005 that explore the utility of different trading mechanisms. However, the ratio of parameters to prices in these models remains one-to-one: citet:blumeLearningBeRational1982 specifically indicate that signals and prices must be paired in order for their model of Bayesian learning to function (pages 343-344). Similarly, citet:admatiNoisyRationalExpectations1985 extends the rational expectations framework to multiple assets, but with $K$ assets there are $K$ prices, preserving the one-to-one ratio between unknowns and signals. As such, these models do not extend to situations where price is determined by more than one valuation parameter: since there is a one-to-one mapping between the underlying parameter and price, it is trivial for an investor to determine whether price conveys new information and how to incorporate that information into her own estimate. If the price an investor observes is consistent with her univariate prior, she rightly believes that she has learned all that she needs to know. A media article reaffirming that belief has no affect on her trading.

  However, it is not clear that this pattern extends to a multivariate prior. If there are multiple combined values of parameters that can lead to the same price, then investors 1) cannot perfectly infer from price movements which parameter requires revision and 2) cannot perfectly infer from information about parameters what the price response should be. As a result, price no longer conveys perfect information and no longer requires the introduction of noise to prevent perfect learning.

  citet:gelsominLearningHypothesisRevisited2023 make this point forcefully in a recent discussion of the ``Learning Hypothesis'' --- the premise that managers learn decision-relevant private information by observing outsiders' trading as reflected in stock prices. They identify three key assumptions underlying this literature: (1) outsiders have private, relevant information; (2) outsiders' trading impounds the value implications of that information into prices; and (3) managers can /extract or infer/ the private information from the resulting stock prices. While the first two assumptions are well-supported, Gelsomin and Hutton note that the third is not: ``There is no empirical proxy that directly demonstrates managerial learning... managerial learning from stock prices is simply /inferred or assumed/ from the documented changes in investment sensitivity to price.'' Their metaphor is apt: predicting the shape of an ice cube from a bowl of water is easy (the forward problem), but inferring the original ice configuration from a bowl of water is impossible (the inverse problem) --- many different shapes produce the same outcome. This is precisely the structural identification problem I formalize below. citet:bondRealEffectsFinancial2012 draw a related distinction between ``forecasting price efficiency'' (price is useful for predicting aggregate cash flows) and ``revelatory price efficiency'' (price is useful for informing specific real decisions). Aggregate price convergence delivers the former; it does not deliver the latter when the security's value depends on multiple parameters.

** Related work on multi-dimensional uncertainty

  The mathematical principle underlying my study --- that a lower-dimensional signal cannot uniquely encode a higher-dimensional state --- was established in the general equilibrium literature on rational expectations. citet:radnerRationalExpectationsEquilibrium1979 showed that fully-revealing rational expectations equilibria exist generically when the dimension of the price space is at least as large as the dimension of the state space. citet:allenStrictRationalExpectations1982 stated this dimensional condition explicitly, and citet:jordanGenericExistenceRational1982 proved the converse: when the dimension of private information states exceeds the dimension of the price space, fully revealing equilibria /generically do not exist/. citet:pietraTradeRevelationInformation2008 subsequently characterized the partially revealing equilibria that arise in this higher-dimensional case.

  It is important to understand precisely what these papers show and do not show. The ``prices'' in Radner and Jordan are the /vector/ of commodity prices across an entire multi-commodity economy, not the price of a single security. Their ``states'' are states of nature that determine endowments, preferences, and technologies across the economy. Their results are /existence theorems/ for general equilibrium: they ask whether there exists an equilibrium price /function/ --- a mapping from states to price vectors --- that is injective (one-to-one), so that observing the price vector uniquely identifies the underlying state. They show that such equilibria exist generically when the price vector has at least as many dimensions as the state space, and generically do not exist otherwise. They do not model investor /learning/ --- there are no dynamics, no updating rules, and no convergence process. They do not ask what happens when the condition is violated; Jordan simply shows that fully-revealing equilibria cannot generically exist in that case.

  The models that followed in the finance literature maintained the dimensional condition by construction. citet:grossmanImpossibilityInformationallyEfficient1980, citet:diamondInformationAggregationNoisy1981, and citet:verrecchiaConsensusBeliefsInformation1980 all model a single security whose value depends on a single unknown parameter, producing a one-to-one mapping that is perturbed only by noise. citet:admatiNoisyRationalExpectations1985 extends the framework to multiple assets, but with $K$ assets there are $K$ prices, preserving the one-to-one ratio. citet:blumeLearningBeRational1982 explicitly require that signals and prices be paired for Bayesian learning to function (pages 343--344).

  Yet for any single security, the dimensional condition is /trivially and always violated/. A stock's value depends on earnings persistence, growth rates, discount rates, accrual quality, and numerous other parameters --- $n$ unknowns --- but the market produces only a single price. The system is structurally underdetermined regardless of noise, agent sophistication, or market microstructure. The theoretical literature has avoided confronting this by modeling single-parameter securities (or, equivalently, by adding securities until the price vector matches the state space). The empirical literature has proceeded as if the problem does not apply, routinely assuming that investors learn individual parameters from aggregate price movements.

  My study addresses this gap. I apply the mathematical principle established by Radner and Jordan to the specific, practical context they did not consider: a single security with $n$ valuation parameters and a single price. I model investor learning dynamics, demonstrate computationally what happens (aggregate convergence coexists with component-level non-identification), measure how component errors scale with $n$, and connect the result to the assumptions embedded in empirical accounting and finance research.

  Several applied papers build models in which a single price aggregates multiple unknowns, though each studies a different consequence of this structure. citet:averyMultidimensionalUncertaintyHerd1998 show that with a single dimension of uncertainty, a single price mechanism prevents herding, but with two or three dimensions of uncertainty, herding and mispricing arise precisely because a single price cannot disentangle the multiple dimensions. Their focus is on herd behavior as a consequence of this identification failure, whereas I focus on the limits of individual investor learning. citet:goldsteinInformationDiversityComplementarities2015a model a security whose value depends on two fundamentals, showing that different traders informed about different fundamentals create strategic complementarities in information acquisition; their model explicitly features the dimensionality mismatch (two unknowns, one price) but focuses on complementarities rather than on measuring component-level learning failure. citet:sockinInformationalFrictionsCommodity2015 study commodity producers who cannot distinguish supply from demand shocks in a single commodity price, generating feedback amplification --- a clean applied example of the 2-unknowns-from-1-signal problem. In the macroeconomics literature, citet:jonathanjadamsMacroeconomicModelsIncomplete2024 introduces a /Sufficient Idiosyncrasy Condition/ (SIC) for equilibrium uniqueness in models with endogenous signals, showing that aggregate signals such as asset prices necessarily fail this condition because aggregation zeroes out idiosyncratic variation. Adams's framework concerns the macroeconomic setting --- whether a system of aggregate signals across an economy can identify the underlying state --- rather than the single-security problem I study. However, the underlying mathematical mechanism is the same: when a signal is a pure aggregate, it cannot be inverted to recover the individual components that produced it.

  In the accounting literature, citet:gelsominLearningHypothesisRevisited2023 directly question the assumption that managers can extract individual information from aggregate stock prices, calling it the critical unvalidated premise of the ``Learning Hypothesis'' literature. Their analysis identifies a structural gap: there is no direct evidence that managers (or investors) actually recover individual information components from price; the literature merely /infers/ learning from changes in investment sensitivity to price. citet:ramananPromotingInformativenessStaggered2015 provide formal support for this concern, showing that a firm releasing multiple pieces of information simultaneously cannot learn from the market's reaction which piece the market is responding to; staggered release allows each piece to be separately priced. This paper directly establishes that aggregate simultaneous pricing prevents learning about individual information components, and provides disclosure-side support for the structural constraint I identify from the investor-learning side. The accrual anomaly literature (citet:sloanStockPricesFully1996) documents that stock prices behave as if investors fixate on total earnings without distinguishing the differential persistence of accruals and cash flows --- empirical evidence consistent with the structural identification problem, though the literature has not connected this pattern to the dimensional constraint.

  citet:godeAllocativeEfficiencyMarkets1993 show that ``zero-intelligence'' traders in a double auction can achieve near-perfect allocative efficiency through the market mechanism alone, even without any learning or information processing. Their result demonstrates that market institutions can substitute for individual rationality in producing efficient /prices/. However, Gode and Sunder's traders have fixed, known private values and do not update beliefs; their setting involves no information asymmetry and no learning from price. The entire agent-based simulation literature on information aggregation, including recent work by citet:jamalEmergenceInformationAggregation2024 and the comprehensive survey by citet:axtellAgentBasedModelingEconomics2025, models fundamentals as single-dimensional. No prior simulation study asks whether traders can learn individual components of a multi-parameter fundamental from a single price. My study fills this gap.

  Several other studies examine settings where a single signal imperfectly communicates multidimensional information, though the impediment to learning is /noise/ rather than /structural underidentification/. citet:felthamPerformanceMeasureCongruity1994 show that a single performance measure cannot capture multi-dimensional agent effort in a contracting setting, and citet:fischerReportingBias2000 study how reporting bias distorts a single earnings signal. In each case, the perturbation to learning arises from exogenous noise added to a fundamentally /identified/ system: remove the noise and the signal perfectly reveals the unknown. My study identifies a different mechanism: the underidentification is /structural/, arising from the dimensionality mismatch between the parameter space ($n$ unknowns) and the signal space (a single price). Even in the complete absence of noise, a single price cannot uniquely determine the individual parameters. This distinction between /noisy identification/ and /structural non-identification/ has not been drawn in the market learning literature.

* Model

  I begin by formally stating the assumptions of my model. I then present an agent-based simulation that implements these assumptions in code, allowing the model to be replicated and extended.

** Formal Setup

  Consider a single risky security whose fundamental value $V$ is determined by $n$ valuation parameters:

\begin{assumption}[Security Value]
\label{a:security}
The security has a true value $V = \sum_{i=1}^{n} \theta_i$, where $\boldsymbol{\theta} = (\theta_1, \ldots, \theta_n)$ is the vector of valuation parameters. Each $\theta_i$ is drawn independently from $\mathcal{N}(0, 1)$.
\end{assumption}

\begin{assumption}[Investor Types]
\label{a:investors}
There are $N$ investors indexed by $j = 1, \ldots, N$. A fraction $\lambda \in (0,1)$ are \emph{informed} and the remainder are \emph{uninformed}. The informed/uninformed status of each investor is fixed throughout the trading process.
\end{assumption}

\begin{assumption}[Information Endowments]
\label{a:information}
Each informed investor $j \in \mathcal{I}$ knows the true parameter vector: $\hat{\boldsymbol{\theta}}^j = \boldsymbol{\theta}$. Each uninformed investor $j \in \mathcal{U}$ holds a prior $\hat{\boldsymbol{\theta}}^j = (\hat{\theta}_1^j, \ldots, \hat{\theta}_n^j)$, where each $\hat{\theta}_i^j$ is drawn independently from $\mathcal{N}(0, 1)$.
\end{assumption}

Note that I set the informed fraction exogenously rather than deriving it from an information acquisition decision as in GS. This is because my study is concerned with what happens /after/ some investors have become informed --- specifically, how well uninformed investors can learn individual parameters from the price signal generated by trading. The information acquisition decision is a separate question, addressed by GS, that does not bear on the identification problem I study.

\begin{assumption}[Market Price]
\label{a:price}
The market maintains a single scalar price $p_t$ at each time $t$. The initial price is $p_0 = V + \eta$, where $\eta \sim \mathcal{N}(0,1)$, so that price starts near but not at the true value. The price is updated according to a simple order imbalance rule:
\begin{equation}
p_{t+1} = p_t + \delta \cdot \text{sgn}\left(\sum_{j=1}^{N} d_j^t \right)
\end{equation}
where $\delta = 0.01$ is the tick size and $d_j^t \in \{-1, 0, 1\}$ is investor $j$'s order at time $t$.
\end{assumption}

\begin{assumption}[Trading Rule]
\label{a:trading}
Each investor submits a unit order based on the comparison of her aggregate prior to the current price:
\begin{equation}
d_j^t = \begin{cases} 1 & \text{if } \sum_{i=1}^{n} \hat{\theta}_i^j > p_t \\ -1 & \text{if } \sum_{i=1}^{n} \hat{\theta}_i^j < p_t \\ 0 & \text{if } \sum_{i=1}^{n} \hat{\theta}_i^j = p_t \end{cases}
\end{equation}
\end{assumption}

Note that I adopt a simple unit-demand trading rule rather than the continuous demand functions in GS, which depend on risk aversion parameters. The identification problem I study does not depend on demand elasticity: whether an investor trades 1 share or 100, the price signal contains only aggregate information. Also note that because informed investors trade on $\sum_i \theta_i = V$ and constitute a majority ($\lambda > 0.5$), the order imbalance will tend to push $p_t$ toward $V$, ensuring price convergence.

\begin{assumption}[Belief Updating]
\label{a:updating}
Informed investors do not update. Uninformed investors update their prior at time $t$ if price fails to move toward their prior (indicating that their prior is inconsistent with the majority of investors). When an uninformed investor $j$ updates, she:
1. Selects a parameter index $k$ uniformly at random from her uninformed parameters.
2. Computes the inferred value of $\theta_k$ from price, holding her other parameter estimates fixed:
\begin{equation}
\tilde{\theta}_k^j = p_t - \sum_{i \neq k} \hat{\theta}_i^j
\end{equation}
3. Updates her estimate by averaging with the inferred value:
\begin{equation}
\hat{\theta}_k^{j,\text{new}} = \frac{\hat{\theta}_k^j + \tilde{\theta}_k^j}{2}
\end{equation}
\end{assumption}

I emphasize that the choice of averaging as an updating rule is deliberately simple. My results do not depend on this specific rule. The core result --- that individual parameter estimates do not converge to their true values --- follows from the structure of the information environment, as I now show.

** The Identification Problem

The following proposition characterizes the fundamental limitation of learning individual parameters from an aggregate price signal.

\begin{proposition}[Structural Non-Identification]
\label{prop:nonid}
Let $V = \sum_{i=1}^{n} \theta_i$ and suppose that the market price $p$ converges to $V$. For $n = 1$, observing $p = V$ uniquely determines $\theta_1 = V$. For $n > 1$, the set of parameter vectors consistent with the observed price is
\begin{equation}
\mathcal{S}(p) = \left\{ \boldsymbol{\theta}' \in \mathbb{R}^n : \sum_{i=1}^{n} \theta_i' = p \right\}
\end{equation}
which is an $(n-1)$-dimensional hyperplane in $\mathbb{R}^n$. In particular, $|\mathcal{S}(p)| = \infty$ for $n > 1$.
\end{proposition}

This result is immediate from the structure of the problem. The key implication is that no updating rule --- whether averaging, OLS, or full Bayesian inference --- can uniquely recover the parameter vector $\boldsymbol{\theta}$ from the scalar price $p$ when $n > 1$. The system has $n$ unknowns and one equation, leaving $n - 1$ degrees of freedom. This is not a matter of noise or bounded rationality; it is a constraint on the information content of the signal itself. Note that this condition is trivially violated for any security whose value depends on more than one parameter --- which is to say, for any real security.

The mathematical principle that a lower-dimensional signal space cannot encode a higher-dimensional state space was established in abstract general equilibrium by citet:radnerRationalExpectationsEquilibrium1979 and citet:jordanGenericExistenceRational1982, who showed that fully-revealing rational expectations equilibria cannot generically exist when the price vector has fewer dimensions than the state space. However, their results concern the existence of equilibrium price /functions/ across multi-commodity economies --- they do not model investor learning, do not characterize what happens when the condition fails, and do not address the single-security setting. Proposition \ref{prop:nonid} applies this principle to the specific context of a single security with $n$ valuation parameters, and the simulation that follows demonstrates what investors' parameter estimates actually look like when they attempt to learn from an aggregate signal that cannot identify the individual components.

This structural non-identification is qualitatively different from the impediments to learning studied in the noisy rational expectations literature. In GS, noise traders perturb the price signal, but the underlying system is identified: removing the noise would allow perfect recovery of $\theta$. In my setting, even in the complete absence of noise --- even if price converges exactly to $V$ --- the individual parameters remain unrecoverable from price alone. The ``noise'' in my model is endogenous and structural, arising from the dimensionality mismatch between the information space and the signal space.

** Departures from Grossman and Stiglitz (1980)

My model departs from GS in several respects, which I discuss here.

/Information acquisition./ In GS, investors choose whether to become informed based on the cost of information and the informativeness of price. In my model, the informed fraction is exogenous. This simplification is appropriate because my research question concerns the /mechanism/ of learning from price, not the /incentive/ to become informed. Setting $\lambda$ exogenously is equivalent to examining GS at a particular equilibrium point and asking what uninformed investors can learn at that point.

/Noise traders./ GS require noise traders to prevent price from perfectly revealing $\theta$, which would eliminate the incentive to become informed. My model has no noise traders. This is not an oversight but a feature of the multi-parameter setting: the identification problem itself prevents perfect revelation of individual parameters, making exogenous noise unnecessary for the result. In the single-parameter case, my model /does/ achieve perfect convergence (consistent with GS without noise traders), which serves as the appropriate benchmark for the multi-parameter case.

/Demand functions./ GS use continuous demand functions derived from CARA utility maximization. I use unit-demand trading for simplicity. Since the identification problem is a property of the /information structure/ (one signal, $n$ unknowns), not of the demand structure, continuous demand would change the rate of price convergence but not the impossibility of recovering individual parameters from the aggregate price.

/Belief formation./ Uninformed investors' initial priors are drawn independently from $\mathcal{N}(0,1)$, the same distribution that generates the true parameters. As such, priors are calibrated to the distribution of fundamentals, though individual investors' priors will generally not equal the true values.

** Simulation Implementation

I now present the simulation that implements the model above. The code serves two purposes: it provides a concrete, executable specification of the model, and it enables replication and extension of my results.

  Following the assumptions stated above, I create two types of investor. Operationally, a fully informed investor's prior is equal to the true value of the security. An uninformed investor's prior consists of independent draws from $\mathcal{N}(0,1)$. The following function creates either an informed or uninformed investor, depending on its arguments:

\singlespacing
#+BEGIN_SRC clojure :results value silent
  (defn make-investor
    ([n] ;; Makes an uninformed agent (Assumption 3)
     {:prior (vec (repeatedly n (fn [] {:informed? false :value (draw-round)})))
      :id (uuid)})
    ([v fully?] ;; Makes an informed agent from a vector of parameters
     {:prior
      (if fully?
        (mapv (fn [pr] {:informed? true :value pr}) v)
        (let [i (rand-int (count v))]
          (assoc (:prior (make-investor (count v)))
                 i
                 {:informed? true :value (get v i)})
          ))
      :id (uuid)})
    )
#+END_SRC
\doublespacing

See [[#a_util][Utilities]] in the Appendices for definitions of helper functions such as draw-round.

When called with an integer, /n/, the above function creates an uninformed investor with a randomly-generated prior containing /n/ parameters (Assumption \ref{a:information}). When called with a vector prior /v/ and with /fully?/ set to true, the function creates a fully informed investor whose prior is set to the vector prior. The function also contains an option to create a partially informed investor: if /fully?/ is set to false, the function randomly chooses to make the investor informed about one parameter in the vector prior.

As stated in Assumption \ref{a:investors}, I set the number of informed investors to a fixed fraction $\lambda$ of the total. Consistent with the view that price constitutes an average consensus belief of traders (citet:verrecchiaConsensusBeliefsInformation1980), I posit and find that $\lambda > 0.5$ results in consistent convergence to true price. I set $\lambda = 0.6$ and $N = 500$, yielding 300 informed and 200 uninformed investors. The following variables and functions create a vector of investors according to this design:

\singlespacing
#+BEGIN_SRC clojure :results value silent
  (def investor-num 500) ;; N = 500 (Assumption 2)
  (def inform-frac 0.6) ;; lambda = 0.6 (Assumption 2)
  (defn make-investor-list
    [n inf-prior]
    (into [] (concat (repeatedly (* investor-num inform-frac)
                                 (fn [] (make-investor inf-prior true)))
                     (repeatedly (* (- 1 inform-frac) investor-num)
                                 (fn [] (make-investor n))))))
#+END_SRC
\doublespacing

These investors trade in a simulated market. The following function creates the market, implementing Assumptions \ref{a:security} and \ref{a:price}:

\singlespacing
#+BEGIN_SRC clojure :results value silent
(defn make-market
  [n]
  (let [security (vec (repeatedly n draw-round)) ;; theta_i ~ N(0,1), rounded
        start-price (+ (draw-round) (reduce + security))] ;; p_0 = V + eta
    {:security security
     :price start-price
     :sp [start-price]
     :investors (make-investor-list n security)}
    ))
#+END_SRC
\doublespacing

The argument /n/ specifies the number of parameters $n$ that determine the value of the security, and thus the number of parameters in each investor's prior. Parameter values are drawn from $\mathcal{N}(0, 1)$ and rounded to two decimal places (establishing a minimum tick size of 0.01). The starting price is set by summing the valuation parameters and adding a draw from $\mathcal{N}(0, 1)$, so that $p_0 = V + \eta$. The function then creates the investors as specified above.

The following functions update the market price based on investor demand for shares. As stated in Assumptions \ref{a:trading} and \ref{a:price}, investors submit unit orders $d_j^t \in \{-1, 0, 1\}$ based on whether their aggregate prior exceeds the current price, and the market adjusts price by $\pm \delta$ based on the sign of the net order imbalance.

\singlespacing
#+BEGIN_SRC clojure :results value silent

  (defn- order-update
    [m]
    (let [;; Implements Assumption 5: d_j^t based on prior vs. price
          pe (reduce + (mapv (fn [a]
                               (let [prior (reduce + (prior-vals a))]
                                 (cond
                                   (> (:price m) prior) -1
                                   (< (:price m) prior) 1
                                   :else 0)))
                             (:investors m)))]
      ;; Implements Assumption 4: p_{t+1} = p_t + delta * sgn(sum of orders)
      (+ (:price m) (cond
                      (> pe 0) 0.01
                      (< pe 0) -0.01
                      :else 0)))
    )

  (defn rand-prior-update
    [m pred upd]
    (mapv (fn [a]
            ;; the predicate determines
            ;; if the agent updates (Assumption 6).
            (let [pred (pred m a)]
              (cond
                ;; if agent is informed or predicate is not satisfied,
                ;; do not update.
                (or (not pred) (informed-agent? a)) a
                ;; otherwise, randomly select an uninformed parameter
                ;; and apply the update function (Assumption 6, steps 1-3).
                :else (let [pri (:prior a)
                            ;; Step 1: select parameter k uniformly at random
                            i ((fn [v]
                                 (let [r (rand-int (count v))]
                                   (cond
                                     (every? :informed? v) nil
                                     (:informed? (get v r)) (recur v)
                                     :else r)
                                   )) pri)
                            sel-pri (get pri i)
                            ;; Step 2: compute inferred value
                            ;; tilde-theta_k = p_t - sum_{i != k} hat-theta_i
                            adjust-price-for-prior
                            (- (:price m)
                               (- (reduce + (map :value pri))
                                  (:value sel-pri)))]
                        ;; Step 3: average current estimate with inferred value
                        (assoc a :prior
                               (update
                                pri
                                i
                                #(assoc
                                  %
                                  :value
                                  (upd adjust-price-for-prior sel-pri))))))))
          (:investors m)))

  ;; does price move towards the agent's prior?
  (defn does-not-move-toward?
    [m a]
    (let [abs-val (fn [p] (Math/abs (- (reduce + (prior-vals a)) p)))]
      (not (< (abs-val (:price m)) (abs-val (last (:sp m)))))
      )
    )

  (defn market-update
    [m]
    (-> m
        ;; adds price to history
        (assoc :sp (conj (:sp m) (:price m)))
        ;; runs the order update function above
        (assoc :price (order-update m))
        ;; updates investors (Assumption 6)
        (assoc :investors (rand-prior-update
                           m
                           ;; predicate: update if price does not move toward prior
                           does-not-move-toward?
                           ;; update function: average current with inferred value
                           (fn [p prior] (/ (+ (:value prior) p) 2))))
        )
    )
#+END_SRC
\doublespacing

As stated in Assumption \ref{a:updating}, informed investors do not update. Uninformed investors observe the period-over-period price change and decide to revise a parameter of their prior if the price fails to move towards what they deem to be the correct price. Otherwise, they assume that their prior is accurate.

When their prior contains only a single parameter ($n = 1$), uninformed investors update that parameter. Otherwise, uninformed investors are unable to distinguish from price movements which parameter of their prior is incorrect --- this is a direct consequence of the identification problem stated in Proposition \ref{prop:nonid} --- and revise a random parameter from their prior vector. They compute the inferred value of the selected parameter by subtracting their estimates of all other parameters from the observed price, then average their current estimate with this inferred value. As a result, uninformed investors slowly adjust their prior to match the price signal they receive, but their parameter-level adjustments are based on an incomplete decomposition of the price signal.

The following code initializes the market and allows investors to trade in rounds until the market converges on a price:

\singlespacing
#+BEGIN_SRC clojure :results value silent

  ;; the market is presumed to have converged
  ;; when the price exhibits no more than
  ;; two values over 10 trading rounds.
  (defn converge?
    [m]
    (some #(< % 3) (map (comp count frequencies) (partition 10 1 (:sp m))))
    )

  ;; run market-update if the market has not converged.
  ;; s indicates the number of valuation parameters.
  ;; n indicates the number of markets to initialize.
  (defn iterate-markets
    [s n]
    (map #(take-while (comp not converge?) (iterate market-update %))
         (take n (repeatedly #(make-market s)))))

#+END_SRC
\doublespacing

The /converge?/ function calculates a rolling window of length 10 on the market's price history and counts the number of unique prices observed. If that number is less than 3, the function concludes that the market has converged; because I have selected a tick size of $\delta = 0.01$, some markets converge on a pattern where they move up and down between two prices that are different by only that amount, but price is functionally unchanged period over period.

* Results
  I first present results when price reflects a single valuation parameter as in GS. The following code generates a single market with a single parameter and iterates trading until the price converges:

\singlespacing

#+BEGIN_SRC clojure :results value silent

  (def m1 (first (iterate-markets 1 1)))
  (price-plot m1)

#+END_SRC
\doublespacing

Note that market parameters are random, so subsequent runs of the same code will result in different market evolutions. Nonetheless, the convergence results for this market, presented in Figure [[fig:1-param-price]], are representative of a standard evolution.

#+BEGIN_CENTER
[Figure [[fig:1-param-price]] here]
#+END_CENTER

Informed investors are displayed in orange. Their prior is fixed at the true value $V = \theta_1$. Consistent with GS, the uninformed investors observe price movements and update their prior over time so that both uninformed investors and price converge to the correct value. This market converged in slightly over 120 trading rounds, which is more than usual for my simulation; on average it takes about 87 rounds. Note that the rate of convergence is likely to be slower than what one would observe in practice, since I only allow a maximum price adjustment of $\delta = 0.01$ per trading round.

Importantly, in the single-parameter case the system is exactly identified: there is one unknown ($\theta_1$) and one signal ($p$). Price convergence to $V$ implies convergence of the parameter estimate to $\theta_1$, as Proposition \ref{prop:nonid} predicts.

I now extend the above simulation to incorporate multiple parameters. The following code generates a market with a two-parameter security vector ($n = 2$) and investors with two-parameter priors and iterates trading until the price converges:

\singlespacing
#+BEGIN_SRC clojure :results value silent

  (def m2 (first (iterate-markets 2 1)))
  (price-plot m2)

#+END_SRC
\doublespacing

Figure [[fig:2-param-price]] shows the convergence results.

#+BEGIN_CENTER
[Figure [[fig:2-param-price]] here]
#+END_CENTER

In keeping with GS, price again converges on the correct value $V = \theta_1 + \theta_2$ and uninformed investors correctly update their aggregate priors to agree with informed investors on the correct price. As a result, the market does indeed price all available information about the security.

This is, however, a distinctly different statement from investors and the market having priced each individual parameter. The following code plots the prior of each investor as the price converges. The x-axis shows the value for $\theta_1$ and the y-axis the value for $\theta_2$.

\singlespacing
#+BEGIN_SRC clojure :results value silent
  ;; The vector argument indicates the progress to convergence.
  ;; So 0 indicates the first round, 1 the final round.
  ;; 0.2 indicates 20% of the way to the final round.
  ;; The final numeric parameter designates the number of columns
  ;; for the combined plot.
  (plot-snap m2 [0 0.2 0.4 0.6 0.8 1] 3)

#+END_SRC
\doublespacing

Figure [[fig:2-param-investors]] shows the results. Uninformed investors start with diffuse priors and undergo steady convergence, as before. However, uninformed investors converge only on the /sum/ of their prior, producing a fitted line that passes through the true aggregate value but maintaining diffusion on the individual parameters. This is precisely the $(n-1)$-dimensional hyperplane $\mathcal{S}(p)$ described in Proposition \ref{prop:nonid}: in two dimensions, it is a line $\hat{\theta}_1 + \hat{\theta}_2 = V$. Since price only communicates the sum of the parameters, any prior that produces that sum is perceived as equally valid by an uninformed investor.

#+BEGIN_CENTER
[Figure [[fig:2-param-investors]] here]
#+END_CENTER

As in citet:verrecchiaConsensusBeliefsInformation1980, investors do not have to agree on parameter values. The market could still be said to have a correct consensus view of each parameter if, in the course of their updating, investors reach the correct average values. The two-parameter value of the security in this market is:
#+BEGIN_SRC clojure :results value :exports results :eval never-export
(:security (last m2))
#+END_SRC

#+RESULTS:
| 0.26 | -0.2 |

The following function calculates the average of investors' estimates for each parameter in the valuation vector:

\singlespacing
#+BEGIN_SRC clojure :results output silent

  (defn avg-prior
    [m]
    (map (fn [n] (/ (reduce + (map #(get-in % [:prior n :value]) (:investors m)))
                    (count (:investors m))))
         (range (count (:security m)))))

#+END_SRC
\doublespacing

The average two-parameter prior across all investors is:
#+BEGIN_SRC clojure :results value :exports results :eval never-export

  (avg-prior (last m2))

#+END_SRC

#+RESULTS:
| 0.1893936029394628 | -0.12848297427298758 |

So the average error for each of the two parameters is:
#+BEGIN_SRC clojure :results value :exports results :eval never-export

(map #(- %1 %2) (:security (last m2)) (avg-prior (last m2)))

#+END_SRC

#+RESULTS:
| 0.0706063970605372 | -0.07151702572701243 |

The total summed error is roughly zero, consistent with market convergence on an efficient price, but the errors on individual parameters are not zero. Note that the errors are approximately equal in magnitude but opposite in sign: the overestimation of $\theta_1$ is compensated by an underestimation of $\theta_2$. This is a direct consequence of the identification constraint --- any parameter vector on the hyperplane $\hat{\theta}_1 + \hat{\theta}_2 = V$ produces the correct aggregate price, so errors in individual parameters must net to zero. As such, although price serves as an aggregator for imperfect individual information sets, the aggregate of investors' beliefs does not reflect the true value of the individual parameters. The market cannot be said to have correctly priced individual parameters of the valuation vector.

Next I examine whether the error in valuing parameters increases as the number of parameters increases above two. I vary the number of parameters between two and 10 and create a sample of 500 markets for each value. As above, I average priors across all investors to get the market's consensus estimate of each parameter. Then, I calculate the sum of squared errors for the parameter vector, scaled by the number of parameters, for each market, and average this error across the sample of 500 markets:

\begin{equation}
\text{MSE}(n) = \frac{1}{500} \sum_{m=1}^{500} \frac{1}{n} \sum_{i=1}^{n} \left(\theta_i^m - \bar{\hat{\theta}}_i^m \right)^2
\end{equation}

where $\theta_i^m$ is the true value of parameter $i$ in market $m$ and $\bar{\hat{\theta}}_i^m$ is the average estimate across all investors.

\singlespacing
#+NAME: mean-error
#+BEGIN_SRC clojure :results value table :eval never-export

  (defn sse-avg
    [m]
    (/ (reduce + (map #(* (- %1 %2) (- %1 %2))
                      (:security m) (avg-prior m)))
       (count (:security m))))
  (def sse-avg-by-size (mapv (fn [s]
                              (map sse-avg
                                   (map last (iterate-markets s 500))))
                            (rest (map inc (range 10)))))

  (vec (conj (map #(vector %1 %2 %3 %4)
                  (vec (rest (mapv inc (range 10))))
                  (mapv (comp #(round2 3 %) average) sse-avg-by-size)
                  (vec
                   (conj
                    (map #(round2 3 (:t-stat
                                   (stats/t-test
                                    (get sse-avg-by-size (- % 2))
                                    :y (get sse-avg-by-size 0))))
                         [3 4 5 6 7 8 9 10]) ""))
                  (vec (conj
                        (map #(round2 3 (:t-stat
                                         (stats/t-test
                                          (get sse-avg-by-size (- % 2))
                                          :y (get sse-avg-by-size (- % 3)))))
                             [3 4 5 6 7 8 9 10]) "")))
             ["Market Size"
              "Mean SSE"
              "t-stat - test of difference with market size 2"
              "t-stat - test of difference with market size n-1"]))

#+END_SRC
\doublespacing

As shown in Table [[tbl:sse-errors]], the sum of squared errors across parameters increases with the number of parameters. The increase is, however, nonlinear, increasing most dramatically when moving from two to three parameters. However, increasing the number of parameters above two always results in a statistically higher error compared to the two-parameter case, suggesting that increasing the number of parameters increases the mispricing of individual parameters. This is consistent with Proposition \ref{prop:nonid}: as $n$ grows, the hyperplane $\mathcal{S}(p)$ gains dimensions, and the space of parameter vectors consistent with the observed price expands.

#+BEGIN_CENTER
[Table [[tbl:sse-errors]] here]
#+END_CENTER

* Discussion of Results
  My results suggest that the market can converge on the correct value of a security without establishing a correct estimate for each valuation parameter. As a result, even after market price has converged on the correct value, investors can still be ``surprised'' by information that was previously available to informed investors. This insight has implications for interpreting market responses.

  As an example, according to the framework in citet:tetlockGivingContentInvestor2007 a researcher can distinguish between media articles containing old (previously released and priced) information and media articles reflecting or creating investor sentiment by their price responses. Specifically, the first does not move prices, while the second results in a temporary price movement followed by a reversal.

  Imagine, then, that a company issues an earnings release. This release contains not only earnings, but also another piece of value-relevant information, resulting in a price movement that reflects both of these components of value simultaneously. Following the earnings release, a journalist writes an opinion piece in which she articulates the true value that should be assigned to earnings. Under the standard efficient markets hypothesis, this information should be considered stale and not move prices. However, according to my model the value reported by the journalist will differ from the consensus value that investors have assigned to earnings. As a result, those investors who have imperfectly learned this value from price believe that they are observing new information and revise their estimates. They could, for instance, substitute the journalist's reported value for their own and thereby arrive at a correct estimate for one of the two valuation parameters. Since they have no information to suggest that they should revise the other valuation parameter, this estimate is not revised.

  As a result, these investors believe that the correct price of the security has changed in light of new information and trade based on that belief, affecting price. Subsequent to this change in price, the informed investors who already knew the information in the article observe that the security is mispriced and start trading back to fundamental value.

  Uninformed investors now believe (correctly) that they have learned the correct valuation of earnings. As a result, they interpret the price movement back to fundamental value as information they can use to revise the second parameter in their valuation model. As they learn that parameter from price, the price returns to the correct value, but the market has also achieved a correct valuation of each valuation parameter as well.

  My model, then, suggests that price movements that might otherwise be dismissed as ``noise'' can actually reflect investor learning. Price reactions can and should occur to seemingly ``stale'' information if it enables investors to directly update parameters that they could only imperfectly learn through price, or if it allows them to better decide how to link observed price movements to parameters. citet:tetlockAllNewsThats2011 provides direct evidence of this pattern: using over 350,000 news stories, he finds that stock returns respond to stale news (stories textually similar to recent coverage), and that individual investors trade /more aggressively/ on stale news than on fresh news. Under standard efficient-markets reasoning, this behavior is anomalous. Under structural non-identification, it is rational: investors who cannot determine from price alone which components are already priced will naturally respond to any signal --- even a recycled one --- that helps them attribute portions of the aggregate to specific fundamentals.

  Whether these temporary fluctuations in price are considered impairments to market efficiency depends on whether the objective of markets is to achieve and maintain a perfectly correct price, even if market participants do not fully understand how that price is determined, or to communicate information between investors.

** Post-earnings-announcement drift as a decomposition problem

  The structural identification problem also offers a new perspective on post-earnings-announcement drift (PEAD), one of the most robust anomalies in finance. citet:bernardPostEarningsAnnouncementDriftDelayed1989 documented that after earnings are announced, cumulative abnormal returns continue to drift in the direction of the earnings surprise for 60 or more trading days. The standard interpretation is that investors underreact to earnings news --- they fail to fully process the implications of current earnings for future earnings.

  The structural non-identification result suggests a different mechanism. Consider an investor observing an earnings surprise. To respond optimally, she must determine what portion of the surprise represents genuinely new information versus what was already reflected in the pre-announcement price. But the pre-announcement price is an aggregate signal that conflates all valuation parameters. The investor cannot decompose it to verify which components were already priced. Faced with this uncertainty, the rational response is to revise gradually: incorporate some of the surprise immediately, then wait for additional signals --- subsequent disclosures, analyst reports, trading by informed investors --- to resolve the decomposition. This gradual revision produces exactly the drift pattern that Bernard and Thomas document.

  This reinterpretation has an important implication: PEAD may not reflect cognitive underreaction or processing failure. Instead, it may reflect the rational response of investors who understand, implicitly or explicitly, that they cannot fully assess the information content of an earnings surprise relative to what was already in price. The drift occurs as supplementary signals arrive and help investors resolve the decomposition problem that the aggregate price signal alone could not solve.

  Relatedly, citet:sloanStockPricesFully1996 documents that stock prices behave as if investors fixate on total earnings without distinguishing between the differential persistence of accruals and cash flows. The ``earnings fixation hypothesis'' holds that investors treat aggregate earnings as a sufficient statistic rather than decomposing it into components with different implications for future value. This is precisely the behavior that structural non-identification predicts: when the aggregate signal is all that price conveys, investors rationally treat it as a sufficient statistic because they have no mechanism to recover the individual components from price alone.

** Investor reliance on price over fundamentals

  citet:blankespoorWhyIndividualInvestors2019 exploit the introduction of automated (``robo-journalism'') earnings articles that present both earnings news and trailing stock returns side by side. Despite having earnings information delivered directly to them, individual investors ignore the earnings content and trade based on trailing stock returns. Blankespoor et al. rule out awareness and acquisition costs and attribute this behavior to ``integration costs'' --- the cognitive difficulty of translating component accounting information into a trading decision.

  Structural non-identification offers a deeper explanation. If investors cannot decompose the pre-existing price signal into its component parameters, then they cannot determine how a specific piece of component information (e.g., an earnings number) maps to value relative to what is already priced. Returns, by contrast, /are/ the aggregate signal --- and for a structurally underdetermined system, the aggregate is the only signal that is unambiguously informative. The ``integration cost'' is not purely cognitive; it reflects the genuine structural impossibility of mapping individual accounting components back to their value implications when the security's value depends on multiple parameters. The rational response is to trade on returns --- the one signal whose information content is clear.

  This pattern extends beyond individual investors. citet:hongUnifiedTheoryUnderreaction1999 model a market in which ``newswatchers'' observe private fundamental signals but cannot extract other newswatchers' information from prices. This inability to invert the price signal is precisely the structural non-identification I describe. In their model, information diffuses gradually because agents cannot fully decompose the aggregate, producing initial underreaction that momentum traders exploit. The resulting momentum profits are not evidence of market inefficiency but of rational trading in an environment where the aggregate price signal is structurally uninvertible.

** Empirical connections

  In this light, there are several streams of empirical literature that relate to my results. First, as discussed above, there is evidence that investors access ``stale'' reports in order to provide context for new disclosures (citet:drakeUsefulnessHistoricalAccounting2016a,tetlockAllNewsThats2011). Stale information is valuable precisely because it helps investors solve the decomposition problem: by identifying which components contributed to a prior price movement, a recycled report can enable investors to update parameters they could only imperfectly learn through price.

  Second, investors share information and collaborate on social media, consistent with the need to establish communication channels between investors that go beyond price (citet:pasquarielloSpeculationInformationDisclosure2016,chenWisdomCrowdsValue2014,campbellSkinGamePersonal2019). If price were sufficient to communicate all relevant information, such channels would be unnecessary. The structural identification problem explains why investors seek supplementary signals: each additional information source potentially helps resolve one dimension of the underdetermined system.

  Third, prior studies have found evidence of investor ``inattention'' and delayed pricing in the presence of a large number of competing firm disclosures (citet:hirshleiferLimitedAttentionInformation2003). My model suggests that the price signal may simply be less useful in the presence of competing informational items, leading to delayed pricing even if investors are fully rational. When multiple pieces of information are released simultaneously, the aggregate price response becomes even harder to decompose, amplifying the identification problem.

  Fourth, prior research suggests that earnings response coefficients are smaller than expected, raising the possibility that the initial response to earnings is incomplete (citet:kothariCapitalMarketsResearch2001). Since earnings are seldom released in isolation, market participants may be unable to fully price earnings alone. The structural constraint explains why: when an earnings release is bundled with other value-relevant information, investors cannot determine from the resulting price movement how much to attribute to earnings specifically.

  Fifth, post-earnings-announcement drift (citet:bernardPostEarningsAnnouncementDriftDelayed1989) and the accrual anomaly (citet:sloanStockPricesFully1996) are both consistent with investors who cannot decompose aggregate signals into components. Drift reflects gradual resolution of the decomposition problem as supplementary signals arrive; the accrual anomaly reflects the rational tendency to treat aggregate earnings as a sufficient statistic when component-level decomposition is structurally impossible from price alone.

  Sixth, citet:blankespoorWhyIndividualInvestors2019 document that investors prefer trailing returns over earnings information even when both are presented side by side. This is consistent with investors rationally relying on the aggregate signal --- the only signal whose information content is unambiguous --- rather than attempting a component-level decomposition that the information structure cannot support.

** Structural non-identification versus competing explanations

  The empirical patterns described above --- drift, earnings fixation, return-chasing, and delayed pricing of complex firms --- have been attributed to a variety of mechanisms in the existing literature. The structural non-identification result offers a qualitatively different explanation that subsumes and reinterprets these mechanisms.

  The dominant explanations fall into four categories. First, /information processing costs/: investors find complex firms harder to analyze, so prices adjust more slowly. citet:barinovFirmComplexityPostEarnings2024 document that PEAD is twice as large for conglomerates and eight times as large for firms that organically create new business segments, attributing this to the higher cost of becoming informed about multi-segment firms. citet:cohenComplicatedFirms2012a show that returns of standalone firms in a conglomerate's industries predict the conglomerate's future returns, generating a trading strategy with returns of 118 basis points per month. Both papers invoke the Grossman-Stiglitz tradition of costly information acquisition.

  Second, /gradual information diffusion/: firm-specific news reaches the investing public slowly, and analysts serve as conduits that accelerate the process. citet:hongUnifiedTheoryUnderreaction1999 model ``newswatchers'' who observe private signals but cannot extract others' information from prices, producing underreaction that momentum traders exploit. citet:hongBadNewsTravels2000 show that momentum is stronger for low-coverage stocks, consistent with slower diffusion where fewer intermediaries propagate news.

  Third, /behavioral fixation/: investors fixate on aggregate numbers without decomposing them into components. citet:shiEarningsFixation2012 derive from a formal model that the accrual anomaly's profitability is the product of the earnings response coefficient and the persistence gap between cash flows and accruals. They show that the anomaly is strongest where both factors are large.

  Fourth, /additional signals/: supplementary disclosures help investors by providing independent information channels. citet:mohanramAnalystsCashFlowForecasts2014 shows that analyst cash flow forecasts implicitly decompose earnings into components and are associated with the decline of the accrual anomaly. citet:ettredgeImpactSFASNo2005 show that SFAS 131 segment disclosures improved the market's ability to anticipate future earnings.

  Each of these explanations treats the pricing problem as /difficult but in principle solvable/: with better analysts, more attention, faster diffusion, less bias, or additional disclosures, investors could in principle price individual components correctly. The structural non-identification result says something qualitatively different. The problem is not hard --- it is /impossible/ from a single price signal. When $\dim(\text{states}) > \dim(\text{prices})$, no updating rule, however sophisticated, can uniquely recover $n$ parameters from one scalar. The impossibility is mathematical, not cognitive.

  This distinction reframes the existing evidence. What citet:barinovFirmComplexityPostEarnings2024 and citet:cohenComplicatedFirms2012a attribute to ``processing costs'' may reflect structural impossibility: a conglomerate operating in $n$ industries has an $n$-dimensional state, and its single stock price is dimensionally insufficient to reveal the individual fundamentals regardless of analyst effort. What citet:blankespoorWhyIndividualInvestors2019 call ``integration costs'' may not be purely cognitive friction but the rational consequence of an underdetermined system. What citet:hongUnifiedTheoryUnderreaction1999 /assume/ --- that agents cannot invert the price signal --- the structural result /explains/: the price signal is non-invertible because it aggregates multiple fundamentals into a single scalar.

  A particularly instructive finding comes from citet:parkEffectSFAS1312011, who decomposes future earnings into industry-wide and firm-specific components. SFAS 131 segment disclosures improved the market's ability to price the industry-wide component but /not/ the firm-specific component. This asymmetry is difficult to explain under processing-cost or attention stories, which predict uniform improvement. Under structural non-identification, it is predicted: segment disclosure reveals /which industries/ a firm operates in (collapsing the industry dimension) but does not resolve firm-specific dynamics (which require firm-specific signals). Each disclosure resolves the dimensions it directly addresses while leaving orthogonal dimensions intact.

  The structural explanation does not invalidate the existing literature. Investors /do/ face processing costs, /are/ subject to limited attention, and /do/ benefit from additional signals. But these factors operate within a structural constraint that the existing literature has not identified. Processing costs and limited attention determine how efficiently investors use available signals; the structural constraint determines the /ceiling/ on what those signals can reveal. Even with infinite processing capacity and unlimited attention, a single price cannot reveal $n > 1$ parameters. The existing explanations describe the surface behavior; the structural result identifies the information-theoretic root cause.

** The value of supplementary signals: why components matter for predicting future prices

  If the aggregate price is already correct, a natural question arises: what is the value of knowing individual components? The answer lies in the distinction between /current/ value and /future/ value. The aggregate price today reflects $V_{\text{today}} = \sum_{i=1}^{n} \theta_i$ correctly, but the components $\theta_i$ evolve differently over time. Cash flows persist at a higher rate than accruals. Growth rates differ from discount rates. Some components are transitory, others permanent. Tomorrow's value depends on how each component evolves:

\begin{equation}
V_{\text{tomorrow}} = \sum_{i=1}^{n} \alpha_i \theta_i
\end{equation}

where the persistence parameters $\alpha_i$ differ across components.

  An investor who observes only the aggregate $V$ must forecast $V_{\text{tomorrow}}$ using some weighted average persistence rate applied to the sum, effectively treating all components as equally persistent:

\begin{equation}
\hat{V}_{\text{tomorrow}} \approx \bar{\alpha} \cdot V_{\text{today}}
\end{equation}

  An investor who can decompose $V$ into its components can exploit the differential persistence:

\begin{equation}
\hat{V}_{\text{tomorrow}} = \sum_{i=1}^{n} \alpha_i \theta_i \neq \bar{\alpha} \sum_{i=1}^{n} \theta_i
\end{equation}

  These forecasts differ whenever the $\alpha_i$ differ, which is generically the case for any real security. *The trading value of component information is not in knowing today's price better --- it is already correct --- but in predicting how today's value will evolve into tomorrow's price.*

  A simple example illustrates the mechanism. Suppose a security's value depends on two components: an earnings component $\theta_1$ with persistence $\alpha_1 = 0.9$ and a transitory component $\theta_2$ with persistence $\alpha_2 = 0.3$. Today's true values are $\theta_1 = 8$ and $\theta_2 = 2$, so $V = 10$. The market price has converged to 10 --- the aggregate is correct.

  An uninformed investor who observes only $V = 10$ cannot determine how much of the value derives from the persistent component and how much from the transitory one. She might believe $(\theta_1, \theta_2) = (6, 4)$ or $(5, 5)$ or any other point on the line $\theta_1 + \theta_2 = 10$. Each of these decompositions implies a different future value:

  | Believed $(\theta_1, \theta_2)$ | Implied $V_{\text{tomorrow}}$ |
  |------|-----------|
  | $(9, 1)$ | $0.9(9) + 0.3(1) = 8.4$ |
  | $(8, 2)$ | $0.9(8) + 0.3(2) = 7.8$ |
  | $(5, 5)$ | $0.9(5) + 0.3(5) = 6.0$ |
  | $(3, 7)$ | $0.9(3) + 0.3(7) = 4.8$ |

  All four investors agree on today's price ($V = 10$), but their forecasts of tomorrow's price range from 4.8 to 8.4. The correct forecast is 7.8, but only an investor who knows the true decomposition can compute it. The range of possible future values --- from $\alpha_2 \cdot V = 3.0$ (if the entire value is transitory) to $\alpha_1 \cdot V = 9.0$ (if the entire value is persistent) --- is the direct consequence of non-identification. Each point on the solution hyperplane maps to a different $V_{\text{tomorrow}}$.

  Now suppose an earnings release reveals $\theta_1 = 8$. The investor who observes this can compute $\theta_2 = V - \theta_1 = 2$ and forecast $V_{\text{tomorrow}} = 0.9(8) + 0.3(2) = 7.8$ exactly. The supplementary signal has collapsed the solution set from a line (one-dimensional) to a point (zero-dimensional), eliminating all forecast ambiguity. The trading profit comes from the difference between the informed investor's forecast (7.8) and the market's forecast, which is based on whatever average persistence the uninformed investors implicitly apply to the aggregate.

  This example extends naturally to $n$ components. With $n$ components and only the aggregate price observed, the solution set is an $(n-1)$-dimensional hyperplane, and the range of possible future values is correspondingly wide. Each supplementary signal that pins down one component collapses one dimension and narrows the forecast range. The first signal is the most valuable: it reduces the dimensionality from $n-1$ to $n-2$ and eliminates the widest band of forecast uncertainty. Subsequent signals provide diminishing but still positive marginal value.

  This is precisely the mechanism underlying the accrual anomaly documented by citet:sloanStockPricesFully1996. The market observes aggregate earnings $E = \text{CF} + \text{ACC}$ and prices the security correctly given that aggregate. But cash flows ($\alpha_{\text{CF}}$ high) are more persistent than accruals ($\alpha_{\text{ACC}}$ low), so a firm with high accruals and low cash flows has a current price that is too high relative to its /future/ value. An investor who can decompose $E$ into cash flows and accruals can predict this reversion and trade profitably. The market, unable to decompose the aggregate, implicitly forecasts with $\bar{\alpha}$ and is systematically wrong about future values.

  The same logic explains the profitability of trading on post-earnings-announcement drift. An earnings surprise identifies a change in a specific component ($\Delta\theta_{\text{earnings}}$). An investor who observes the surprise directly knows /which/ component changed and can predict how the security's value will evolve given the persistence of that component. The market, observing only the aggregate price change, cannot attribute it to a specific component and therefore adjusts gradually as supplementary signals arrive. The drift represents the period during which the market is resolving the decomposition problem, and informed investors can trade profitably during that window.

  More generally, each supplementary signal that resolves one dimension of the identification problem reduces the dimensionality of the remaining solution set. With price alone, the investor faces $n$ unknowns and one equation: the solution set is an $(n-1)$-dimensional hyperplane. Observing one component directly (e.g., earnings) reduces the system to $n-1$ unknowns and one equation (the remaining components must sum to $V - \theta_{\text{earnings}}$), yielding an $(n-2)$-dimensional solution set. Each additional component signal collapses one further dimension. The system is fully determined only when all $n$ components are independently observed --- a condition that is never met in practice, but that disclosure, analyst reports, and other information channels can /approximate/.

  However, direct component observations are not the only signals that help resolve the identification problem. There are in fact three distinct types of information that constrain the solution set:

  /Component observations/ directly pin down a parameter value: $\theta_i = c$. An earnings disclosure, an analyst's cash flow estimate, or a segment report each provides this type of signal. In the linear algebra of the problem, a component observation eliminates one unknown, collapsing the solution set by one dimension.

  /Structural observations/ reveal not a component value but the /mapping/ from components to price. The earnings response coefficient (ERC) is a canonical example. When an investor observes both an earnings surprise $\Delta\theta_{\text{earnings}}$ and the resulting price response $\Delta V$, the ratio $\Delta V / \Delta\theta_{\text{earnings}}$ provides information about the partial derivative $\partial V / \partial \theta_{\text{earnings}}$ --- how much of a unit change in earnings translates into price. If the ERC is less than one, it indicates that other components moved in the opposite direction, or that the market had already partially incorporated the earnings news, or that earnings have implications for other components (a strong quarter may revise downward an implicit risk premium). These structural coefficients constrain the /shape/ of the solution set: they do not pin down a specific $\theta_i$, but they restrict how the components relate to the aggregate, narrowing the range of plausible decompositions.

  /Relative observations/ arise from comparing price responses across events. If an investor observes that the market responded strongly to an earnings surprise but weakly to a revenue surprise, she can infer something about which components the market had already priced and which dimensions remain unresolved. Each event-study observation, in this framework, is informative not just about the news content of the event but about the /residual structure/ of the identification problem --- which dimensions of the solution set have already been collapsed by prior signals.

  The empirical accounting literature has been estimating structural observations for decades --- every ERC regression, every FERC analysis, every measure of ``price informativeness'' is an estimate of a structural parameter of the mapping from components to price. The framework developed here gives these estimates a new interpretation: they are not merely measures of ``how efficiently'' the market prices earnings, but partial solutions to the identification problem. An investor who knows the ERC for earnings can, when the next price movement occurs, make a better inference about how much of it is attributable to earnings versus other factors. The ERC does not tell you what earnings are; it tells you how earnings /relate/ to the aggregate, which constrains the set of possible decompositions.

  This typology also reframes what it means to possess ``private information.'' The standard assumption in the literature is that private information consists of component observations --- an insider knows $\theta_i$ before the market does. But the framework reveals two additional forms of private information that are equally valuable for resolving the identification problem. A manager who knows her own firm's earnings, costs, and investment plans has extensive component observations. But she also possesses structural knowledge: she knows /how/ these components combine to produce value, which components are persistent and which are transitory, and how changes in one component affect others. This structural knowledge allows her to decompose the price signal in ways that an outside observer, who lacks the structural map, cannot.

  This provides a more precise answer to the question raised by citet:gelsominLearningHypothesisRevisited2023 regarding whether managers learn from price. Managers /can/ learn from price, but only about dimensions they are able to isolate using their supplementary signals --- both component observations and structural knowledge. A manager who knows her own earnings can observe price and infer the market's assessment of everything else: $\theta_{\text{rest}} = V - \theta_{\text{earnings}}$. A manager who additionally knows the persistence structure of her firm can make inferences about future price dynamics that outside investors cannot. But a manager who does not know, say, the market's discount rate or the competitive dynamics of a new market segment still faces an underdetermined system on those dimensions. Gelsomin and Hutton's Assumption 3 --- that managers extract private information from prices --- is not categorically wrong, but it is /conditionally/ true: managers can extract information only along dimensions that their own private signals allow them to decompose. The structural framework specifies both the possibility and the boundary.

  The same logic applies to other market participants. Analysts who specialize in an industry possess structural knowledge about how that industry's components combine and persist, enabling them to decompose prices more effectively than generalists. Institutional investors with proprietary models possess structural estimates (ERCs, factor loadings, persistence parameters) that constrain their solution sets. Retail investors, who typically observe only price and headline news, face the most severe identification problem. This creates a natural hierarchy of decomposition ability --- from managers (most supplementary signals) to specialized analysts to institutional investors to retail investors --- that maps to empirically observed patterns in forecast accuracy and trading performance.

  This framework provides a structural foundation for understanding the value of disclosure. The contribution of each disclosure is not merely ``more information'' in a generic sense; it is the resolution of a specific dimension of the identification problem that price alone cannot resolve. Disaggregated disclosures are more valuable than aggregated ones because each separately reported component collapses one dimension of the solution set. This explains why citet:ramananPromotingInformativenessStaggered2015 finds that staggered information releases are more informative than simultaneous releases: each release, individually priced, resolves one dimension before the next arrives, whereas simultaneous release produces a single aggregate price response that conflates all dimensions.

  The implication for empirical research design is direct: studies that assume investors learn individual parameters from aggregate price movements are implicitly assuming that the identification problem has been resolved. My results suggest that this assumption should be stated explicitly and defended, not taken as a default. The degree to which investors can learn individual parameters depends on the availability of supplementary signals --- direct disclosures, analyst decompositions, media coverage, and social media discussion --- that help resolve the dimensions of the underdetermined system. The structural non-identification result does not imply that investors /never/ learn individual parameters; it implies that they cannot do so from price alone, and that the informational ecosystem surrounding a security determines how many dimensions of the identification problem can be resolved in practice.

* Conclusion
  In this paper I extend prior models, in which investors perfectly learn a single valuation parameter from price, to a setting in which price responds to multiple valuation parameters. I show that this creates a structural identification problem: a single scalar price constrains investors to an $(n-1)$-dimensional hyperplane of parameter vectors, all of which are consistent with the observed price. Using an agent-based simulation, I find that the market continues to converge on the correct price, but that there is significant variation in investors' estimates of the individual valuation parameters. As a result, there remains significant disagreement among investors about the appropriate value of a particular parameter. I conclude that market efficiency in the aggregate, in which market price reflects all available information, is distinct from the market efficiently pricing the individual informational components that lead to that value. My evidence also suggests that individual parameter errors are increasing in the number of parameters.

  The structural non-identification I describe is qualitatively different from the impediments to learning studied in prior models of noisy rational expectations. In those models (citet:grossmanImpossibilityInformationallyEfficient1980, citet:fischerReportingBias2000, citet:felthamPerformanceMeasureCongruity1994), incomplete learning arises because exogenous noise perturbs a fundamentally identified signal; removing the noise would restore perfect learning. In my setting, even in the complete absence of noise, a single price cannot reveal individual parameters when $n > 1$. The mathematical principle that a lower-dimensional signal space cannot encode a higher-dimensional state space was established by citet:radnerRationalExpectationsEquilibrium1979, citet:allenStrictRationalExpectations1982, and citet:jordanGenericExistenceRational1982 as an abstract existence result for multi-commodity general equilibrium. For a single security, this condition is trivially and always violated: any security whose value depends on more than one parameter presents investors with an underdetermined system. Yet neither the theoretical finance literature (which has maintained the dimensional condition by modeling single-parameter securities or adding securities to match) nor the empirical literature (which assumes investors learn individual parameters from price) has drawn this implication. My contribution is to apply this principle to the single-security investor learning problem, to demonstrate computationally that aggregate price convergence coexists with component-level non-identification, to measure how component errors scale with $n$, and to connect the result to the assumptions embedded in empirical accounting and finance research.

  I would like to note that my study does not imply that markets are inefficient and does not definitively show that markets are unable to price individual parameters. I merely point out that the mechanism by which we presume investors to learn multiple underlying parameters from a single signal, price, is not a trivial extension of prevailing models. Given the empirical reality, in which price is forever perturbed by the arrival of diverse information (citet:rollR21988,leeMarketEfficiencyAccounting2001), it is critical to understand the role that price can and cannot play in communicating information between investors.

  The structural result also reframes the extensive empirical literature that attributes pricing anomalies to information processing costs, limited attention, or behavioral fixation. These explanations treat the problem as /difficult but solvable/: with better analysts, more attention, or less bias, investors could price components correctly. The structural constraint is qualitatively different --- it is an impossibility, not a difficulty. What the literature attributes to ``processing costs'' (citet:barinovFirmComplexityPostEarnings2024,cohenComplicatedFirms2012), ``integration costs'' (citet:blankespoorWhyIndividualInvestors2019), or ``gradual diffusion'' (citet:hongBadNewsTravels2000) may reflect the rational response to a structurally underdetermined system. Processing costs, attention, and diffusion speed determine how efficiently investors use available signals, but the structural constraint determines the /ceiling/ on what those signals can reveal. The existing explanations and the structural result are not mutually exclusive, but the structural constraint is more fundamental: it persists even when all behavioral and cognitive frictions are removed.

  I would also note that my model of investor learning is deliberately simple so as to isolate the identification problem from other features of the trading environment. Other models of learning may allow investors to achieve more efficient parameter estimates by, for example, using the time-series of prices or trading volumes to extract additional information. However, no mechanism can allow investors to learn /perfectly/ from a single contemporaneous price when there is more than a single valuation parameter, because the system is structurally underidentified.

  An important implication of structural non-identification is that the value of knowing individual components lies not in assessing current price --- which is already correct in aggregate --- but in predicting /future/ prices. Because components evolve at different rates (cash flows persist more than accruals, growth rates differ from discount rates), an investor who can decompose the aggregate can forecast future values more accurately than one who treats the aggregate as a sufficient statistic. This provides a structural explanation for well-documented anomalies: the accrual anomaly (citet:sloanStockPricesFully1996) arises because the market cannot distinguish high-persistence from low-persistence components; post-earnings-announcement drift (citet:bernardPostEarningsAnnouncementDriftDelayed1989,bernardEvidenceThatStock1990) arises as the market gradually resolves which component changed; and investor reliance on trailing returns over fundamental information (citet:blankespoorWhyIndividualInvestors2019) reflects the rational preference for the aggregate signal when component decomposition is structurally impossible.

  Each supplementary signal --- a disclosure, an analyst report, a media article --- resolves one dimension of the identification problem, reducing the solution set from an $(n-1)$-dimensional hyperplane toward a point. The structural non-identification result thus provides a foundation for understanding the value of disclosure: disaggregated disclosures are valuable not because they contain ``more'' information in a generic sense, but because each separately reported component collapses one dimension of the underdetermined system. Investors are limited in what they can learn from price and likely need to utilize these alternative means to achieve efficient parameter estimates. To the extent that markets are an information technology as well as a means of allocating capital, my study indicates a need for a better understanding of how price interacts with other sources of information to produce investor consensus.

\singlespacing
* Appendices
** Utilities
  :PROPERTIES:
  :CUSTOM_ID: a_util
  :END:
  These variables and functions support the code in the paper. If you are reproducing the code in the paper you should define these variables and functions *first*.

  Like other Lisps, Clojure has a simple standard syntax. Function calls are enclosed in parentheses. The first object within a set of parentheses is called as a function, the remaining objects are arguments. Functions are first-class objects in Clojure, allowing them to be treated as data and passed as arguments. Clojure also supports the use of anonymous functions using the (fn...) or #(...) syntax.

#+BEGIN_SRC clojure :results value silent
  (require '[oz.core :as oz] ;; version "1.6.0-alpha5"
           '[incanter.stats :as stats] ;; version "1.9.3"
           )

  (def norm-mean 0)
  (def norm-std 1)
  ;; Draws from a normal distribution with a mean of norm-mean (defined above)
  ;; and a standard deviation of norm-std (defined above).
  (defn draw-incant-norm
    []
    (stats/sample-normal 1 :mean norm-mean :sd norm-std))

  (defn round2
    "Round a double to the given precision (number of significant digits)"
    [precision d]
    (let [factor (Math/pow 10 precision)]
      (/ (Math/round (* d factor)) factor)))

  ;; Rounds a number to two digits,
  ;; for a minimum tick size of 0.01.
  (defn draw-round
    []
    (round2 2 (draw-incant-norm)))

  (defn average
    [xs]
    (float (/ (apply + xs) (count xs))))
  (defn uuid
    []
    (keyword (str (java.util.UUID/randomUUID))))

  (defn prior-vals
    [a]
    (mapv :value (:prior a)))

  (defn informed-agent?
    [a]
    (some :informed? (:prior a)))

  (defn make-data
    [ms]
    (vec (mapcat #(let [priors (mapv (fn [a] (reduce + (map :value (:prior a))))
                                     (:investors %2))
                        infs (mapv (fn [a] (:informed? (first (:prior a))))
                                   (:investors %2))]
                    (mapv (fn [prior inf] (hash-map :time %1
                                                    :price (:price %2)
                                                    :security
                                                    (reduce + (:security %2))
                                                    :prior prior
                                                    :informed? inf))
                          priors
                          infs))
                 (range (count ms)) ms))
    )

  (defn price-plot
    [m]
    (oz/view! {:height 600
               :width 800
               :data {:values (make-data m)}
               :layer [{:encoding {:x {:field "time"}
                                   :y {:field "prior"}
                                   :color {:field "informed?"}}
                        :mark {:type "point"}}
                       {:encoding {:x {:field "time"}
                                   :y {:field "price"}}
                        :mark {:type "line"}}]
               }))

  (defn make-snap-data
    [ms]
    (vec (mapcat #(let [priors (mapv (fn [a] (prior-vals a))
                                     (:investors %2))
                        infs (mapv (fn [a] (mapv :informed? (:prior a)))
                                   (:investors %2))]
                    (mapv (fn [prior inf] (hash-map :time %1
                                                    :price1 (first (:security %2))
                                                    :price2 (second (:security %2))
                                                    :prior1 (first prior)
                                                    :prior2 (second prior)
                                                    :informed? (if (first inf)
                                                                 true
                                                                 false)
                                                    ))
                          priors
                          infs))
                 (range (count ms)) ms)))

  (defn plot-snap
    [d v col-num]
    (let [sd (make-snap-data d)
          make-plot (fn [n] {:data {:values (filter #(= (:time %) n) sd)}
                             :title (str "round = " n)
                             :layer
                             [{:encoding {:x {:field "prior1"}
                                          :y {:field "prior2"}
                                          :color {:field "informed?"}}
                               :mark {:type "point" :opacity 0.3}}
                              {:encoding {:x {:field "price1"}
                                          :y {:field "price2"}}
                               :mark {:type "point" :shape "square" :size 60}}]
                             })
          length (- (count (distinct (map :time sd))) 1)
          pv (partition col-num (mapv #(int (* % length)) v))]
      (oz/view! {:vconcat (map (fn [row] {:hconcat (map make-plot row)}) pv)})))
#+END_SRC

#+latex: \newpage
\printbibliography


#+latex: \newpage
* Figures and Tables

#+CAPTION: Price convergence for a market with one parameter, as in GS
#+NAME: fig:1-param-price
[[./plots/1-param-price.png]]


#+CAPTION: Price convergence for a market with two parameters
#+NAME: fig:2-param-price
[[./plots/2-param-price.png]]

#+CAPTION: Prior updating by investors with two parameters
#+NAME: fig:2-param-investors
[[./plots/2-param-investors.png]]

#+CAPTION: Sum of Squared Errors as the Number of Parameters Increases
#+NAME: tbl:sse-errors
#+ATTR_LATEX: :environment longtable :align |ccC{3cm}C{3cm}|
|-------------+----------------------------+----------------------------------------------------|
| Number of Parameters | Mean SSE | t-stat - test of difference with market size 2 | t-stat - test of difference with market size n-1 |
|           2 |    0.078 |                                                |                                                  |
|           3 |    0.109 |                                          4.426 |                                            4.426 |
|           4 |    0.129 |                                           7.34 |                                             2.85 |
|           5 |    0.131 |                                          8.406 |                                            0.312 |
|           6 |    0.141 |                                         10.145 |                                            1.812 |
|           7 |    0.139 |                                         10.061 |                                           -0.246 |
|           8 |    0.142 |                                         10.624 |                                            0.418 |
|           9 |    0.137 |                                         10.332 |                                           -0.918 |
|          10 |     0.15 |                                         12.112 |                                             2.74 |
|-------------+----------------------------+----------------------------------------------------|

* Extra :noexport:
# Result for (market-convergence-numbers (mapv inc (range 20))) when the number of markets is 500:
# (86.924
#  89.912
#  88.298
#  87.372
#  90.438
#  89.946
#  90.848
#  93.546
#  88.362
#  89.922
#  94.882
#  87.132
#  88.974
#  93.0
#  90.21
#  89.038
#  86.07
#  90.894
#  84.3
#  87.45)
# Differences are not statistically significant, so it is generally not true that the market takes longer to converge when there are more pieces of information in play.

# Result for average error for uninformed investors as market size grows.
# Code: (map (fn [i] (/ (reduce + (map #(prior-error (last %)) (iterate-markets i 100))) 100)) (map inc (range 20)))
# (0.005397382785367705
#  0.39579183265378426
#  0.41453329430878716
#  0.44119554923490667
#  0.46768149660663433
#  0.4521248587112712
#  0.5086778009442662
#  0.45969876676716326
#  0.4800114462748398
#  0.4840139420813182
#  0.4996159071353425
#  0.49923822423525543
#  0.4879302380814084
#  0.502249419219274
#  0.4844871103781026
#  0.4940053428192927
#  0.525746339625341
#  0.479169751808412
#  0.4730871843721022
#  0.4879026433065603)
